PEMS03
Original data shape (26208, 358, 1)
Trainset:	x-(15701, 12, 358, 1)	y-(15701, 12, 358, 1)
Valset:  	x-(5219, 12, 358, 1)  	y-(5219, 12, 358, 1)
Testset:	x-(5219, 12, 358, 1)	y-(5219, 12, 358, 1)

--------- GWNET ---------
{
    "num_nodes": 358,
    "in_steps": 12,
    "out_steps": 12,
    "train_size": 0.6,
    "val_size": 0.2,
    "lr": 0.001,
    "weight_decay": 0.0001,
    "milestones": [
        115
    ],
    "clip_grad": false,
    "batch_size": 64,
    "max_epochs": 200,
    "use_cl": true,
    "cl_step_size": 2500,
    "load_npz": false,
    "pass_device": true,
    "model_args": {
        "num_nodes": 358,
        "in_dim": 1,
        "out_dim": 12,
        "adj_path": null,
        "adj_type": "doubletransition",
        "device": "cuda:0",
        "dropout": 0.3,
        "gcn_bool": true,
        "addaptadj": true,
        "aptinit": null
    }
}
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
GWNET                                    --                        --
├─ModuleList: 1-1                        --                        --
├─ModuleList: 1-2                        --                        --
├─ModuleList: 1-3                        --                        --
├─ModuleList: 1-4                        --                        --
├─ModuleList: 1-5                        --                        --
├─ModuleList: 1-6                        --                        --
├─Conv2d: 1-7                            [64, 32, 358, 13]         64
├─ModuleList: 1-1                        --                        --
│    └─Conv2d: 2-1                       [64, 32, 358, 12]         2,080
├─ModuleList: 1-2                        --                        --
│    └─Conv2d: 2-2                       [64, 32, 358, 12]         2,080
├─ModuleList: 1-4                        --                        --
│    └─Conv2d: 2-3                       [64, 256, 358, 12]        8,448
├─ModuleList: 1-6                        --                        --
│    └─gcn: 2-4                          [64, 32, 358, 12]         --
│    │    └─nconv: 3-1                   [64, 32, 358, 12]         --
│    │    └─nconv: 3-2                   [64, 32, 358, 12]         --
│    │    └─linear: 3-3                  [64, 32, 358, 12]         3,104
├─ModuleList: 1-5                        --                        --
│    └─BatchNorm2d: 2-5                  [64, 32, 358, 12]         64
├─ModuleList: 1-1                        --                        --
│    └─Conv2d: 2-6                       [64, 32, 358, 10]         2,080
├─ModuleList: 1-2                        --                        --
│    └─Conv2d: 2-7                       [64, 32, 358, 10]         2,080
├─ModuleList: 1-4                        --                        --
│    └─Conv2d: 2-8                       [64, 256, 358, 10]        8,448
├─ModuleList: 1-6                        --                        --
│    └─gcn: 2-9                          [64, 32, 358, 10]         --
│    │    └─nconv: 3-4                   [64, 32, 358, 10]         --
│    │    └─nconv: 3-5                   [64, 32, 358, 10]         --
│    │    └─linear: 3-6                  [64, 32, 358, 10]         3,104
├─ModuleList: 1-5                        --                        --
│    └─BatchNorm2d: 2-10                 [64, 32, 358, 10]         64
├─ModuleList: 1-1                        --                        --
│    └─Conv2d: 2-11                      [64, 32, 358, 9]          2,080
├─ModuleList: 1-2                        --                        --
│    └─Conv2d: 2-12                      [64, 32, 358, 9]          2,080
├─ModuleList: 1-4                        --                        --
│    └─Conv2d: 2-13                      [64, 256, 358, 9]         8,448
├─ModuleList: 1-6                        --                        --
│    └─gcn: 2-14                         [64, 32, 358, 9]          --
│    │    └─nconv: 3-7                   [64, 32, 358, 9]          --
│    │    └─nconv: 3-8                   [64, 32, 358, 9]          --
│    │    └─linear: 3-9                  [64, 32, 358, 9]          3,104
├─ModuleList: 1-5                        --                        --
│    └─BatchNorm2d: 2-15                 [64, 32, 358, 9]          64
├─ModuleList: 1-1                        --                        --
│    └─Conv2d: 2-16                      [64, 32, 358, 7]          2,080
├─ModuleList: 1-2                        --                        --
│    └─Conv2d: 2-17                      [64, 32, 358, 7]          2,080
├─ModuleList: 1-4                        --                        --
│    └─Conv2d: 2-18                      [64, 256, 358, 7]         8,448
├─ModuleList: 1-6                        --                        --
│    └─gcn: 2-19                         [64, 32, 358, 7]          --
│    │    └─nconv: 3-10                  [64, 32, 358, 7]          --
│    │    └─nconv: 3-11                  [64, 32, 358, 7]          --
│    │    └─linear: 3-12                 [64, 32, 358, 7]          3,104
├─ModuleList: 1-5                        --                        --
│    └─BatchNorm2d: 2-20                 [64, 32, 358, 7]          64
├─ModuleList: 1-1                        --                        --
│    └─Conv2d: 2-21                      [64, 32, 358, 6]          2,080
├─ModuleList: 1-2                        --                        --
│    └─Conv2d: 2-22                      [64, 32, 358, 6]          2,080
├─ModuleList: 1-4                        --                        --
│    └─Conv2d: 2-23                      [64, 256, 358, 6]         8,448
├─ModuleList: 1-6                        --                        --
│    └─gcn: 2-24                         [64, 32, 358, 6]          --
│    │    └─nconv: 3-13                  [64, 32, 358, 6]          --
│    │    └─nconv: 3-14                  [64, 32, 358, 6]          --
│    │    └─linear: 3-15                 [64, 32, 358, 6]          3,104
├─ModuleList: 1-5                        --                        --
│    └─BatchNorm2d: 2-25                 [64, 32, 358, 6]          64
├─ModuleList: 1-1                        --                        --
│    └─Conv2d: 2-26                      [64, 32, 358, 4]          2,080
├─ModuleList: 1-2                        --                        --
│    └─Conv2d: 2-27                      [64, 32, 358, 4]          2,080
├─ModuleList: 1-4                        --                        --
│    └─Conv2d: 2-28                      [64, 256, 358, 4]         8,448
├─ModuleList: 1-6                        --                        --
│    └─gcn: 2-29                         [64, 32, 358, 4]          --
│    │    └─nconv: 3-16                  [64, 32, 358, 4]          --
│    │    └─nconv: 3-17                  [64, 32, 358, 4]          --
│    │    └─linear: 3-18                 [64, 32, 358, 4]          3,104
├─ModuleList: 1-5                        --                        --
│    └─BatchNorm2d: 2-30                 [64, 32, 358, 4]          64
├─ModuleList: 1-1                        --                        --
│    └─Conv2d: 2-31                      [64, 32, 358, 3]          2,080
├─ModuleList: 1-2                        --                        --
│    └─Conv2d: 2-32                      [64, 32, 358, 3]          2,080
├─ModuleList: 1-4                        --                        --
│    └─Conv2d: 2-33                      [64, 256, 358, 3]         8,448
├─ModuleList: 1-6                        --                        --
│    └─gcn: 2-34                         [64, 32, 358, 3]          --
│    │    └─nconv: 3-19                  [64, 32, 358, 3]          --
│    │    └─nconv: 3-20                  [64, 32, 358, 3]          --
│    │    └─linear: 3-21                 [64, 32, 358, 3]          3,104
├─ModuleList: 1-5                        --                        --
│    └─BatchNorm2d: 2-35                 [64, 32, 358, 3]          64
├─ModuleList: 1-1                        --                        --
│    └─Conv2d: 2-36                      [64, 32, 358, 1]          2,080
├─ModuleList: 1-2                        --                        --
│    └─Conv2d: 2-37                      [64, 32, 358, 1]          2,080
├─ModuleList: 1-4                        --                        --
│    └─Conv2d: 2-38                      [64, 256, 358, 1]         8,448
├─ModuleList: 1-6                        --                        --
│    └─gcn: 2-39                         [64, 32, 358, 1]          --
│    │    └─nconv: 3-22                  [64, 32, 358, 1]          --
│    │    └─nconv: 3-23                  [64, 32, 358, 1]          --
│    │    └─linear: 3-24                 [64, 32, 358, 1]          3,104
├─ModuleList: 1-5                        --                        --
│    └─BatchNorm2d: 2-40                 [64, 32, 358, 1]          64
├─Conv2d: 1-8                            [64, 512, 358, 1]         131,584
├─Conv2d: 1-9                            [64, 12, 358, 1]          6,156
==========================================================================================
Total params: 264,012
Trainable params: 264,012
Non-trainable params: 0
Total mult-adds (G): 21.89
==========================================================================================
Input size (MB): 1.10
Forward/backward pass size (MB): 3832.35
Params size (MB): 1.06
Estimated Total Size (MB): 3834.51
==========================================================================================

Loss: HuberLoss

CL target length = 1
2023-03-25 20:44:55.337502 Epoch 1  	Train Loss = 18.60502 Val Loss = 112.00969
2023-03-25 20:45:31.091752 Epoch 2  	Train Loss = 15.30130 Val Loss = 111.78223
2023-03-25 20:46:07.159565 Epoch 3  	Train Loss = 13.82055 Val Loss = 111.73942
2023-03-25 20:46:43.326489 Epoch 4  	Train Loss = 13.24143 Val Loss = 111.77020
2023-03-25 20:47:19.534189 Epoch 5  	Train Loss = 13.09902 Val Loss = 111.70725
2023-03-25 20:47:55.784901 Epoch 6  	Train Loss = 12.99591 Val Loss = 111.71073
2023-03-25 20:48:32.062984 Epoch 7  	Train Loss = 12.92143 Val Loss = 111.69200
2023-03-25 20:49:08.333867 Epoch 8  	Train Loss = 12.80475 Val Loss = 111.68894
2023-03-25 20:49:44.596244 Epoch 9  	Train Loss = 12.76682 Val Loss = 111.68634
2023-03-25 20:50:20.838897 Epoch 10  	Train Loss = 12.75126 Val Loss = 111.69239
CL target length = 2
2023-03-25 20:50:57.061306 Epoch 11  	Train Loss = 14.61392 Val Loss = 102.78789
2023-03-25 20:51:33.249512 Epoch 12  	Train Loss = 13.40815 Val Loss = 102.80342
2023-03-25 20:52:09.365142 Epoch 13  	Train Loss = 13.22614 Val Loss = 102.73774
2023-03-25 20:52:45.422540 Epoch 14  	Train Loss = 13.22165 Val Loss = 102.76550
2023-03-25 20:53:21.478305 Epoch 15  	Train Loss = 13.12867 Val Loss = 102.74413
2023-03-25 20:53:57.528761 Epoch 16  	Train Loss = 13.13257 Val Loss = 102.75661
2023-03-25 20:54:33.585313 Epoch 17  	Train Loss = 13.05563 Val Loss = 102.75407
2023-03-25 20:55:09.648644 Epoch 18  	Train Loss = 13.01172 Val Loss = 102.71443
2023-03-25 20:55:45.713324 Epoch 19  	Train Loss = 13.03580 Val Loss = 102.73437
2023-03-25 20:56:21.782802 Epoch 20  	Train Loss = 12.99172 Val Loss = 102.70534
CL target length = 3
2023-03-25 20:56:57.859146 Epoch 21  	Train Loss = 14.18262 Val Loss = 93.97168
2023-03-25 20:57:33.957900 Epoch 22  	Train Loss = 13.41621 Val Loss = 93.78746
2023-03-25 20:58:10.057963 Epoch 23  	Train Loss = 13.34097 Val Loss = 93.77803
2023-03-25 20:58:46.217924 Epoch 24  	Train Loss = 13.30941 Val Loss = 93.83513
2023-03-25 20:59:22.369709 Epoch 25  	Train Loss = 13.28481 Val Loss = 93.81107
2023-03-25 20:59:58.559608 Epoch 26  	Train Loss = 13.20965 Val Loss = 93.76909
2023-03-25 21:00:34.808629 Epoch 27  	Train Loss = 13.16645 Val Loss = 93.79163
2023-03-25 21:01:11.053082 Epoch 28  	Train Loss = 13.20254 Val Loss = 93.81965
2023-03-25 21:01:47.288781 Epoch 29  	Train Loss = 13.17108 Val Loss = 93.89630
2023-03-25 21:02:23.515496 Epoch 30  	Train Loss = 13.07467 Val Loss = 93.75357
CL target length = 4
2023-03-25 21:02:59.769636 Epoch 31  	Train Loss = 13.95812 Val Loss = 84.95284
2023-03-25 21:03:36.006030 Epoch 32  	Train Loss = 13.41373 Val Loss = 84.86714
2023-03-25 21:04:12.233379 Epoch 33  	Train Loss = 13.38338 Val Loss = 84.85983
2023-03-25 21:04:48.439494 Epoch 34  	Train Loss = 13.36053 Val Loss = 84.87844
2023-03-25 21:05:24.587047 Epoch 35  	Train Loss = 13.32203 Val Loss = 84.82521
2023-03-25 21:06:00.687917 Epoch 36  	Train Loss = 13.26535 Val Loss = 84.87467
2023-03-25 21:06:36.738503 Epoch 37  	Train Loss = 13.21710 Val Loss = 84.81722
2023-03-25 21:07:12.743217 Epoch 38  	Train Loss = 13.21057 Val Loss = 84.95004
2023-03-25 21:07:48.735455 Epoch 39  	Train Loss = 13.18325 Val Loss = 84.95827
2023-03-25 21:08:24.735746 Epoch 40  	Train Loss = 13.17855 Val Loss = 84.77171
CL target length = 5
2023-03-25 21:09:00.738385 Epoch 41  	Train Loss = 13.76612 Val Loss = 76.11258
2023-03-25 21:09:36.795248 Epoch 42  	Train Loss = 13.43355 Val Loss = 75.92222
2023-03-25 21:10:12.804398 Epoch 43  	Train Loss = 13.33821 Val Loss = 76.03655
2023-03-25 21:10:48.800796 Epoch 44  	Train Loss = 13.36494 Val Loss = 76.10423
2023-03-25 21:11:24.787996 Epoch 45  	Train Loss = 13.27029 Val Loss = 75.87192
2023-03-25 21:12:00.823805 Epoch 46  	Train Loss = 13.23935 Val Loss = 75.91010
2023-03-25 21:12:36.865530 Epoch 47  	Train Loss = 13.23450 Val Loss = 75.84795
2023-03-25 21:13:12.918378 Epoch 48  	Train Loss = 13.20337 Val Loss = 75.85481
2023-03-25 21:13:48.943717 Epoch 49  	Train Loss = 13.18997 Val Loss = 75.96783
2023-03-25 21:14:24.978049 Epoch 50  	Train Loss = 13.17887 Val Loss = 75.86703
CL target length = 6
2023-03-25 21:15:01.113450 Epoch 51  	Train Loss = 13.65992 Val Loss = 67.13082
2023-03-25 21:15:37.302297 Epoch 52  	Train Loss = 13.41921 Val Loss = 67.01123
2023-03-25 21:16:13.423662 Epoch 53  	Train Loss = 13.30654 Val Loss = 66.97476
2023-03-25 21:16:49.542383 Epoch 54  	Train Loss = 13.32159 Val Loss = 66.99739
2023-03-25 21:17:25.702208 Epoch 55  	Train Loss = 13.27754 Val Loss = 66.96744
2023-03-25 21:18:01.849628 Epoch 56  	Train Loss = 13.23330 Val Loss = 67.03726
2023-03-25 21:18:38.034754 Epoch 57  	Train Loss = 13.24160 Val Loss = 66.94565
2023-03-25 21:19:14.233216 Epoch 58  	Train Loss = 13.18915 Val Loss = 67.04857
2023-03-25 21:19:50.427428 Epoch 59  	Train Loss = 13.15323 Val Loss = 67.03378
2023-03-25 21:20:26.602774 Epoch 60  	Train Loss = 13.18321 Val Loss = 66.93783
CL target length = 7
2023-03-25 21:21:02.731277 Epoch 61  	Train Loss = 13.42554 Val Loss = 58.77791
2023-03-25 21:21:38.830874 Epoch 62  	Train Loss = 13.50905 Val Loss = 58.16852
2023-03-25 21:22:14.929029 Epoch 63  	Train Loss = 13.32729 Val Loss = 58.06346
2023-03-25 21:22:51.021509 Epoch 64  	Train Loss = 13.29717 Val Loss = 58.17349
2023-03-25 21:23:27.105146 Epoch 65  	Train Loss = 13.25075 Val Loss = 58.20527
2023-03-25 21:24:03.175301 Epoch 66  	Train Loss = 13.27549 Val Loss = 58.23992
2023-03-25 21:24:39.271643 Epoch 67  	Train Loss = 13.26056 Val Loss = 58.08600
2023-03-25 21:25:15.431344 Epoch 68  	Train Loss = 13.24869 Val Loss = 58.33549
2023-03-25 21:25:51.530437 Epoch 69  	Train Loss = 13.18253 Val Loss = 58.09826
2023-03-25 21:26:27.605625 Epoch 70  	Train Loss = 13.17559 Val Loss = 57.98295
2023-03-25 21:27:03.669879 Epoch 71  	Train Loss = 13.17204 Val Loss = 58.03754
CL target length = 8
2023-03-25 21:27:39.756815 Epoch 72  	Train Loss = 13.70003 Val Loss = 49.28572
2023-03-25 21:28:15.830770 Epoch 73  	Train Loss = 13.33158 Val Loss = 49.49375
2023-03-25 21:28:51.931108 Epoch 74  	Train Loss = 13.32832 Val Loss = 49.31409
2023-03-25 21:29:28.019828 Epoch 75  	Train Loss = 13.27030 Val Loss = 49.29514
2023-03-25 21:30:04.162677 Epoch 76  	Train Loss = 13.26820 Val Loss = 49.21050
2023-03-25 21:30:40.309518 Epoch 77  	Train Loss = 13.22287 Val Loss = 49.14700
2023-03-25 21:31:16.466400 Epoch 78  	Train Loss = 13.24576 Val Loss = 49.24489
2023-03-25 21:31:52.616174 Epoch 79  	Train Loss = 13.22129 Val Loss = 49.23642
2023-03-25 21:32:28.787244 Epoch 80  	Train Loss = 13.20920 Val Loss = 49.38035
2023-03-25 21:33:04.982841 Epoch 81  	Train Loss = 13.17950 Val Loss = 49.26389
CL target length = 9
2023-03-25 21:33:41.204754 Epoch 82  	Train Loss = 13.66362 Val Loss = 40.55197
2023-03-25 21:34:17.414720 Epoch 83  	Train Loss = 13.32139 Val Loss = 40.43376
2023-03-25 21:34:53.627188 Epoch 84  	Train Loss = 13.30817 Val Loss = 40.34758
2023-03-25 21:35:29.776044 Epoch 85  	Train Loss = 13.30169 Val Loss = 40.37192
2023-03-25 21:36:05.889825 Epoch 86  	Train Loss = 13.24727 Val Loss = 40.42643
2023-03-25 21:36:42.000591 Epoch 87  	Train Loss = 13.20849 Val Loss = 40.29448
2023-03-25 21:37:18.102867 Epoch 88  	Train Loss = 13.21982 Val Loss = 40.39843
2023-03-25 21:37:54.187718 Epoch 89  	Train Loss = 13.19962 Val Loss = 40.28774
2023-03-25 21:38:30.196750 Epoch 90  	Train Loss = 13.19977 Val Loss = 40.38266
2023-03-25 21:39:06.195199 Epoch 91  	Train Loss = 13.19303 Val Loss = 40.35319
CL target length = 10
2023-03-25 21:39:42.292062 Epoch 92  	Train Loss = 13.59056 Val Loss = 31.57708
2023-03-25 21:40:18.447934 Epoch 93  	Train Loss = 13.33866 Val Loss = 31.67258
2023-03-25 21:40:54.532806 Epoch 94  	Train Loss = 13.30780 Val Loss = 31.60862
2023-03-25 21:41:30.579419 Epoch 95  	Train Loss = 13.26252 Val Loss = 31.55283
2023-03-25 21:42:06.654554 Epoch 96  	Train Loss = 13.25950 Val Loss = 31.62015
2023-03-25 21:42:42.731540 Epoch 97  	Train Loss = 13.24418 Val Loss = 31.47237
2023-03-25 21:43:18.829386 Epoch 98  	Train Loss = 13.28511 Val Loss = 31.42220
2023-03-25 21:43:54.995323 Epoch 99  	Train Loss = 13.21655 Val Loss = 31.47290
2023-03-25 21:44:31.193218 Epoch 100  	Train Loss = 13.20401 Val Loss = 31.50423
2023-03-25 21:45:07.321858 Epoch 101  	Train Loss = 13.20698 Val Loss = 31.84602
CL target length = 11
2023-03-25 21:45:43.438488 Epoch 102  	Train Loss = 13.54369 Val Loss = 22.76847
2023-03-25 21:46:19.582045 Epoch 103  	Train Loss = 13.29456 Val Loss = 22.56984
2023-03-25 21:46:55.747579 Epoch 104  	Train Loss = 13.33760 Val Loss = 22.63564
2023-03-25 21:47:31.926107 Epoch 105  	Train Loss = 13.26966 Val Loss = 22.73562
2023-03-25 21:48:08.130549 Epoch 106  	Train Loss = 13.26572 Val Loss = 22.51894
2023-03-25 21:48:44.343203 Epoch 107  	Train Loss = 13.28963 Val Loss = 22.67878
2023-03-25 21:49:20.503960 Epoch 108  	Train Loss = 13.24967 Val Loss = 22.89142
2023-03-25 21:49:56.622505 Epoch 109  	Train Loss = 13.21827 Val Loss = 22.68184
2023-03-25 21:50:32.648175 Epoch 110  	Train Loss = 13.23170 Val Loss = 22.72533
2023-03-25 21:51:08.651377 Epoch 111  	Train Loss = 13.19576 Val Loss = 22.64201
CL target length = 12
2023-03-25 21:51:44.691082 Epoch 112  	Train Loss = 13.50634 Val Loss = 14.37909
2023-03-25 21:52:20.720056 Epoch 113  	Train Loss = 13.32642 Val Loss = 13.84720
2023-03-25 21:52:56.735569 Epoch 114  	Train Loss = 13.27682 Val Loss = 14.17863
2023-03-25 21:53:32.749050 Epoch 115  	Train Loss = 13.29333 Val Loss = 15.35700
2023-03-25 21:54:08.761004 Epoch 116  	Train Loss = 13.06056 Val Loss = 13.55767
2023-03-25 21:54:44.752654 Epoch 117  	Train Loss = 12.98774 Val Loss = 13.57536
2023-03-25 21:55:20.780510 Epoch 118  	Train Loss = 12.97872 Val Loss = 13.55554
2023-03-25 21:55:56.810605 Epoch 119  	Train Loss = 12.97625 Val Loss = 13.57996
2023-03-25 21:56:32.834920 Epoch 120  	Train Loss = 12.98028 Val Loss = 13.54719
2023-03-25 21:57:08.870576 Epoch 121  	Train Loss = 12.97239 Val Loss = 13.58339
2023-03-25 21:57:44.933195 Epoch 122  	Train Loss = 12.97079 Val Loss = 13.54869
2023-03-25 21:58:20.999587 Epoch 123  	Train Loss = 12.96367 Val Loss = 13.54498
2023-03-25 21:58:57.055410 Epoch 124  	Train Loss = 12.96769 Val Loss = 13.59419
2023-03-25 21:59:33.125782 Epoch 125  	Train Loss = 12.95802 Val Loss = 13.59187
2023-03-25 22:00:09.208119 Epoch 126  	Train Loss = 12.95308 Val Loss = 13.53693
2023-03-25 22:00:45.321499 Epoch 127  	Train Loss = 12.95649 Val Loss = 13.55417
2023-03-25 22:01:21.448821 Epoch 128  	Train Loss = 12.94502 Val Loss = 13.55665
2023-03-25 22:01:57.589525 Epoch 129  	Train Loss = 12.94587 Val Loss = 13.51002
2023-03-25 22:02:33.735180 Epoch 130  	Train Loss = 12.94836 Val Loss = 13.55562
2023-03-25 22:03:09.891771 Epoch 131  	Train Loss = 12.94645 Val Loss = 13.54401
2023-03-25 22:03:46.000670 Epoch 132  	Train Loss = 12.94104 Val Loss = 13.57575
2023-03-25 22:04:22.035161 Epoch 133  	Train Loss = 12.93817 Val Loss = 13.56119
2023-03-25 22:04:58.019167 Epoch 134  	Train Loss = 12.93563 Val Loss = 13.51722
2023-03-25 22:05:33.999505 Epoch 135  	Train Loss = 12.93812 Val Loss = 13.57365
2023-03-25 22:06:09.985696 Epoch 136  	Train Loss = 12.93665 Val Loss = 13.58588
2023-03-25 22:06:45.974367 Epoch 137  	Train Loss = 12.93095 Val Loss = 13.55022
2023-03-25 22:07:21.945216 Epoch 138  	Train Loss = 12.92627 Val Loss = 13.54130
2023-03-25 22:07:57.901402 Epoch 139  	Train Loss = 12.93449 Val Loss = 13.53429
Early stopping at epoch: 139
Best at epoch 129:
Train Loss = 12.94587
Train RMSE = 21.34831, MAE = 13.21523, MAPE = 12.36634
Val Loss = 13.51002
Val RMSE = 22.36186, MAE = 14.03725, MAPE = 13.12261
--------- Test ---------
All Steps RMSE = 25.62278, MAE = 14.57478, MAPE = 14.27234
Step 1 RMSE = 20.78631, MAE = 12.05595, MAPE = 11.77949
Step 2 RMSE = 22.28123, MAE = 12.76704, MAPE = 12.44628
Step 3 RMSE = 23.46852, MAE = 13.36524, MAPE = 13.10135
Step 4 RMSE = 24.40284, MAE = 13.83828, MAPE = 13.62306
Step 5 RMSE = 25.10345, MAE = 14.23295, MAPE = 14.24661
Step 6 RMSE = 25.69619, MAE = 14.59404, MAPE = 14.63175
Step 7 RMSE = 26.26402, MAE = 14.95267, MAPE = 15.08495
Step 8 RMSE = 26.79242, MAE = 15.27066, MAPE = 15.17566
Step 9 RMSE = 27.24687, MAE = 15.53692, MAPE = 15.14710
Step 10 RMSE = 27.66535, MAE = 15.79634, MAPE = 15.19044
Step 11 RMSE = 28.04246, MAE = 16.06729, MAPE = 15.35222
Step 12 RMSE = 28.48298, MAE = 16.42010, MAPE = 15.48914
