METRLA
Trainset:	x-(23974, 12, 207, 3)	y-(23974, 12, 207, 1)
Valset:  	x-(3425, 12, 207, 3)  	y-(3425, 12, 207, 1)
Testset:	x-(6850, 12, 207, 3)	y-(6850, 12, 207, 1)

--------- STID ---------
{
    "num_nodes": 207,
    "in_steps": 12,
    "out_steps": 12,
    "train_size": 0.7,
    "val_size": 0.1,
    "time_of_day": true,
    "day_of_week": true,
    "lr": 0.002,
    "weight_decay": 0.0001,
    "milestones": [
        1,
        25,
        50
    ],
    "lr_decay_rate": 0.5,
    "batch_size": 64,
    "max_epochs": 200,
    "early_stop": 20,
    "use_cl": false,
    "model_args": {
        "num_nodes": 207,
        "input_len": 12,
        "output_len": 12,
        "input_dim": 3,
        "embed_dim": 32,
        "node_dim": 32,
        "temp_dim_tid": 32,
        "temp_dim_diw": 32,
        "time_of_day_size": 288,
        "day_of_week_size": 7,
        "if_node": true,
        "if_time_in_day": true,
        "if_day_in_week": true,
        "num_layer": 3
    }
}
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
STID                                     --                        --
├─Conv2d: 1-1                            [64, 32, 207, 1]          1,184
├─Sequential: 1-2                        [64, 128, 207, 1]         --
│    └─MultiLayerPerceptron: 2-1         [64, 128, 207, 1]         --
│    │    └─Conv2d: 3-1                  [64, 128, 207, 1]         16,512
│    │    └─ReLU: 3-2                    [64, 128, 207, 1]         --
│    │    └─Dropout: 3-3                 [64, 128, 207, 1]         --
│    │    └─Conv2d: 3-4                  [64, 128, 207, 1]         16,512
│    └─MultiLayerPerceptron: 2-2         [64, 128, 207, 1]         --
│    │    └─Conv2d: 3-5                  [64, 128, 207, 1]         16,512
│    │    └─ReLU: 3-6                    [64, 128, 207, 1]         --
│    │    └─Dropout: 3-7                 [64, 128, 207, 1]         --
│    │    └─Conv2d: 3-8                  [64, 128, 207, 1]         16,512
│    └─MultiLayerPerceptron: 2-3         [64, 128, 207, 1]         --
│    │    └─Conv2d: 3-9                  [64, 128, 207, 1]         16,512
│    │    └─ReLU: 3-10                   [64, 128, 207, 1]         --
│    │    └─Dropout: 3-11                [64, 128, 207, 1]         --
│    │    └─Conv2d: 3-12                 [64, 128, 207, 1]         16,512
├─Conv2d: 1-3                            [64, 12, 207, 1]          1,548
==========================================================================================
Total params: 101,804
Trainable params: 101,804
Non-trainable params: 0
Total mult-adds (G): 1.35
==========================================================================================
Input size (MB): 1.91
Forward/backward pass size (MB): 86.06
Params size (MB): 0.41
Estimated Total Size (MB): 88.37
==========================================================================================

Loss: MaskedMAELoss

2023-04-10 17:02:18.880849 Epoch 1  	Train Loss = 3.91353 Val Loss = 3.22441
2023-04-10 17:02:24.875778 Epoch 2  	Train Loss = 3.28490 Val Loss = 3.11442
2023-04-10 17:02:31.046195 Epoch 3  	Train Loss = 3.17710 Val Loss = 3.06013
2023-04-10 17:02:37.165795 Epoch 4  	Train Loss = 3.11855 Val Loss = 3.01466
2023-04-10 17:02:43.346616 Epoch 5  	Train Loss = 3.08506 Val Loss = 2.98299
2023-04-10 17:02:49.572147 Epoch 6  	Train Loss = 3.05709 Val Loss = 2.99416
2023-04-10 17:02:55.802494 Epoch 7  	Train Loss = 3.04266 Val Loss = 3.01701
2023-04-10 17:03:02.218160 Epoch 8  	Train Loss = 3.02373 Val Loss = 2.96793
2023-04-10 17:03:08.239918 Epoch 9  	Train Loss = 3.00767 Val Loss = 2.97523
2023-04-10 17:03:14.419398 Epoch 10  	Train Loss = 3.00134 Val Loss = 2.94578
2023-04-10 17:03:20.564261 Epoch 11  	Train Loss = 2.99268 Val Loss = 2.95153
2023-04-10 17:03:26.841183 Epoch 12  	Train Loss = 2.98233 Val Loss = 2.95080
2023-04-10 17:03:32.997103 Epoch 13  	Train Loss = 2.97933 Val Loss = 2.95144
2023-04-10 17:03:39.198623 Epoch 14  	Train Loss = 2.97037 Val Loss = 2.97158
2023-04-10 17:03:45.397748 Epoch 15  	Train Loss = 2.96448 Val Loss = 2.96946
2023-04-10 17:03:51.587124 Epoch 16  	Train Loss = 2.96027 Val Loss = 2.93737
2023-04-10 17:03:57.618029 Epoch 17  	Train Loss = 2.95300 Val Loss = 2.94038
2023-04-10 17:04:03.998231 Epoch 18  	Train Loss = 2.94985 Val Loss = 2.94297
2023-04-10 17:04:10.493746 Epoch 19  	Train Loss = 2.94790 Val Loss = 2.94660
2023-04-10 17:04:16.732175 Epoch 20  	Train Loss = 2.94834 Val Loss = 2.92148
2023-04-10 17:04:22.885177 Epoch 21  	Train Loss = 2.93973 Val Loss = 2.94288
2023-04-10 17:04:29.181581 Epoch 22  	Train Loss = 2.94047 Val Loss = 2.96794
2023-04-10 17:04:35.474080 Epoch 23  	Train Loss = 2.93684 Val Loss = 2.93060
2023-04-10 17:04:41.547479 Epoch 24  	Train Loss = 2.93431 Val Loss = 2.92126
2023-04-10 17:04:47.672993 Epoch 25  	Train Loss = 2.93253 Val Loss = 2.92608
2023-04-10 17:04:53.898210 Epoch 26  	Train Loss = 2.90608 Val Loss = 2.89868
2023-04-10 17:05:00.225948 Epoch 27  	Train Loss = 2.90538 Val Loss = 2.91374
2023-04-10 17:05:06.550351 Epoch 28  	Train Loss = 2.90313 Val Loss = 2.91855
2023-04-10 17:05:12.788840 Epoch 29  	Train Loss = 2.90194 Val Loss = 2.92478
2023-04-10 17:05:18.986444 Epoch 30  	Train Loss = 2.90209 Val Loss = 2.91879
2023-04-10 17:05:24.841309 Epoch 31  	Train Loss = 2.90046 Val Loss = 2.91282
2023-04-10 17:05:30.925692 Epoch 32  	Train Loss = 2.89985 Val Loss = 2.91115
2023-04-10 17:05:36.905331 Epoch 33  	Train Loss = 2.89911 Val Loss = 2.91357
2023-04-10 17:05:42.554258 Epoch 34  	Train Loss = 2.89742 Val Loss = 2.90888
2023-04-10 17:05:48.756624 Epoch 35  	Train Loss = 2.89647 Val Loss = 2.90775
2023-04-10 17:05:55.026272 Epoch 36  	Train Loss = 2.89724 Val Loss = 2.91859
2023-04-10 17:06:01.282801 Epoch 37  	Train Loss = 2.89489 Val Loss = 2.91379
2023-04-10 17:06:07.361216 Epoch 38  	Train Loss = 2.89314 Val Loss = 2.91388
2023-04-10 17:06:13.706695 Epoch 39  	Train Loss = 2.89484 Val Loss = 2.91995
2023-04-10 17:06:19.937466 Epoch 40  	Train Loss = 2.89270 Val Loss = 2.90429
2023-04-10 17:06:26.174740 Epoch 41  	Train Loss = 2.89168 Val Loss = 2.89766
2023-04-10 17:06:32.020200 Epoch 42  	Train Loss = 2.89085 Val Loss = 2.91464
2023-04-10 17:06:38.087478 Epoch 43  	Train Loss = 2.88972 Val Loss = 2.92435
2023-04-10 17:06:44.401704 Epoch 44  	Train Loss = 2.88996 Val Loss = 2.89206
2023-04-10 17:06:50.475909 Epoch 45  	Train Loss = 2.88923 Val Loss = 2.91908
2023-04-10 17:06:56.743953 Epoch 46  	Train Loss = 2.88817 Val Loss = 2.89087
2023-04-10 17:07:03.161772 Epoch 47  	Train Loss = 2.88663 Val Loss = 2.91204
2023-04-10 17:07:09.212584 Epoch 48  	Train Loss = 2.88785 Val Loss = 2.90701
2023-04-10 17:07:15.574387 Epoch 49  	Train Loss = 2.88556 Val Loss = 2.90224
2023-04-10 17:07:21.957461 Epoch 50  	Train Loss = 2.88646 Val Loss = 2.90467
2023-04-10 17:07:28.297721 Epoch 51  	Train Loss = 2.87338 Val Loss = 2.89889
2023-04-10 17:07:34.501684 Epoch 52  	Train Loss = 2.87139 Val Loss = 2.89922
2023-04-10 17:07:40.963177 Epoch 53  	Train Loss = 2.87079 Val Loss = 2.90261
2023-04-10 17:07:47.382938 Epoch 54  	Train Loss = 2.87065 Val Loss = 2.89837
2023-04-10 17:07:53.788398 Epoch 55  	Train Loss = 2.87141 Val Loss = 2.90504
2023-04-10 17:08:00.180347 Epoch 56  	Train Loss = 2.87024 Val Loss = 2.90372
2023-04-10 17:08:06.554637 Epoch 57  	Train Loss = 2.86882 Val Loss = 2.89844
2023-04-10 17:08:12.958618 Epoch 58  	Train Loss = 2.86981 Val Loss = 2.90460
2023-04-10 17:08:19.365849 Epoch 59  	Train Loss = 2.86863 Val Loss = 2.89199
2023-04-10 17:08:25.746349 Epoch 60  	Train Loss = 2.86893 Val Loss = 2.90879
2023-04-10 17:08:32.052449 Epoch 61  	Train Loss = 2.86829 Val Loss = 2.89774
2023-04-10 17:08:38.475998 Epoch 62  	Train Loss = 2.86892 Val Loss = 2.90442
2023-04-10 17:08:44.768701 Epoch 63  	Train Loss = 2.86864 Val Loss = 2.89958
2023-04-10 17:08:51.022779 Epoch 64  	Train Loss = 2.86750 Val Loss = 2.89857
2023-04-10 17:08:57.386751 Epoch 65  	Train Loss = 2.86715 Val Loss = 2.90566
2023-04-10 17:09:03.809357 Epoch 66  	Train Loss = 2.86835 Val Loss = 2.90152
Early stopping at epoch: 66
Best at epoch 46:
Train Loss = 2.88817
Train RMSE = 5.76365, MAE = 2.81574, MAPE = 7.66455
Val Loss = 2.89087
Val RMSE = 6.18278, MAE = 2.94391, MAPE = 8.51441
--------- Test ---------
All Steps RMSE = 6.49962, MAE = 3.12334, MAPE = 9.14207
Step 1 RMSE = 4.09008, MAE = 2.31387, MAPE = 5.80041
Step 2 RMSE = 4.97425, MAE = 2.61197, MAPE = 6.90841
Step 3 RMSE = 5.54832, MAE = 2.80984, MAPE = 7.72826
Step 4 RMSE = 5.98074, MAE = 2.96070, MAPE = 8.39240
Step 5 RMSE = 6.32384, MAE = 3.08155, MAPE = 8.92829
Step 6 RMSE = 6.61033, MAE = 3.18206, MAPE = 9.37385
Step 7 RMSE = 6.84949, MAE = 3.26893, MAPE = 9.76924
Step 8 RMSE = 7.03775, MAE = 3.33928, MAPE = 10.08334
Step 9 RMSE = 7.20189, MAE = 3.40056, MAPE = 10.35072
Step 10 RMSE = 7.34155, MAE = 3.45538, MAPE = 10.58310
Step 11 RMSE = 7.46037, MAE = 3.50247, MAPE = 10.78732
Step 12 RMSE = 7.57377, MAE = 3.55357, MAPE = 10.99976
Inference time: 0.49 s
