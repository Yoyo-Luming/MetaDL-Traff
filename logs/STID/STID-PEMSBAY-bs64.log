PEMSBAY
Trainset:	x-(36465, 12, 325, 3)	y-(36465, 12, 325, 1)
Valset:  	x-(5209, 12, 325, 3)  	y-(5209, 12, 325, 1)
Testset:	x-(10419, 12, 325, 3)	y-(10419, 12, 325, 1)

--------- STID ---------
{
    "num_nodes": 325,
    "in_steps": 12,
    "out_steps": 12,
    "train_size": 0.7,
    "val_size": 0.1,
    "time_of_day": true,
    "day_of_week": true,
    "lr": 0.002,
    "weight_decay": 0.0001,
    "milestones": [
        1,
        50,
        80
    ],
    "lr_decay_rate": 0.5,
    "batch_size": 64,
    "max_epochs": 200,
    "early_stop": 30,
    "use_cl": false,
    "model_args": {
        "num_nodes": 325,
        "input_len": 12,
        "output_len": 12,
        "input_dim": 3,
        "embed_dim": 32,
        "node_dim": 32,
        "temp_dim_tid": 32,
        "temp_dim_diw": 32,
        "time_of_day_size": 288,
        "day_of_week_size": 7,
        "if_node": true,
        "if_time_in_day": true,
        "if_day_in_week": true,
        "num_layer": 3
    }
}
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
STID                                     --                        --
├─Conv2d: 1-1                            [64, 32, 325, 1]          1,184
├─Sequential: 1-2                        [64, 128, 325, 1]         --
│    └─MultiLayerPerceptron: 2-1         [64, 128, 325, 1]         --
│    │    └─Conv2d: 3-1                  [64, 128, 325, 1]         16,512
│    │    └─ReLU: 3-2                    [64, 128, 325, 1]         --
│    │    └─Dropout: 3-3                 [64, 128, 325, 1]         --
│    │    └─Conv2d: 3-4                  [64, 128, 325, 1]         16,512
│    └─MultiLayerPerceptron: 2-2         [64, 128, 325, 1]         --
│    │    └─Conv2d: 3-5                  [64, 128, 325, 1]         16,512
│    │    └─ReLU: 3-6                    [64, 128, 325, 1]         --
│    │    └─Dropout: 3-7                 [64, 128, 325, 1]         --
│    │    └─Conv2d: 3-8                  [64, 128, 325, 1]         16,512
│    └─MultiLayerPerceptron: 2-3         [64, 128, 325, 1]         --
│    │    └─Conv2d: 3-9                  [64, 128, 325, 1]         16,512
│    │    └─ReLU: 3-10                   [64, 128, 325, 1]         --
│    │    └─Dropout: 3-11                [64, 128, 325, 1]         --
│    │    └─Conv2d: 3-12                 [64, 128, 325, 1]         16,512
├─Conv2d: 1-3                            [64, 12, 325, 1]          1,548
==========================================================================================
Total params: 101,804
Trainable params: 101,804
Non-trainable params: 0
Total mult-adds (G): 2.12
==========================================================================================
Input size (MB): 3.00
Forward/backward pass size (MB): 135.12
Params size (MB): 0.41
Estimated Total Size (MB): 138.52
==========================================================================================

Loss: MaskedMAELoss

2023-04-10 18:45:03.214905 Epoch 1  	Train Loss = 1.95712 Val Loss = 1.88344
2023-04-10 18:45:14.273423 Epoch 2  	Train Loss = 1.68093 Val Loss = 1.76835
2023-04-10 18:45:25.739314 Epoch 3  	Train Loss = 1.63886 Val Loss = 1.75666
2023-04-10 18:45:37.306132 Epoch 4  	Train Loss = 1.61273 Val Loss = 1.72201
2023-04-10 18:45:49.110178 Epoch 5  	Train Loss = 1.59642 Val Loss = 1.70438
2023-04-10 18:46:00.939899 Epoch 6  	Train Loss = 1.58204 Val Loss = 1.70102
2023-04-10 18:46:12.455688 Epoch 7  	Train Loss = 1.57247 Val Loss = 1.66891
2023-04-10 18:46:24.562325 Epoch 8  	Train Loss = 1.56744 Val Loss = 1.66997
2023-04-10 18:46:36.678721 Epoch 9  	Train Loss = 1.55815 Val Loss = 1.66813
2023-04-10 18:46:48.733434 Epoch 10  	Train Loss = 1.55217 Val Loss = 1.67166
2023-04-10 18:47:00.651706 Epoch 11  	Train Loss = 1.54918 Val Loss = 1.66346
2023-04-10 18:47:12.701998 Epoch 12  	Train Loss = 1.54290 Val Loss = 1.68506
2023-04-10 18:47:24.611052 Epoch 13  	Train Loss = 1.53897 Val Loss = 1.65342
2023-04-10 18:47:36.716550 Epoch 14  	Train Loss = 1.53741 Val Loss = 1.65362
2023-04-10 18:47:49.156633 Epoch 15  	Train Loss = 1.53215 Val Loss = 1.65002
2023-04-10 18:48:01.049454 Epoch 16  	Train Loss = 1.53221 Val Loss = 1.63878
2023-04-10 18:48:13.048191 Epoch 17  	Train Loss = 1.52924 Val Loss = 1.68560
2023-04-10 18:48:24.952938 Epoch 18  	Train Loss = 1.52829 Val Loss = 1.65333
2023-04-10 18:48:36.931676 Epoch 19  	Train Loss = 1.52527 Val Loss = 1.63249
2023-04-10 18:48:48.953149 Epoch 20  	Train Loss = 1.52260 Val Loss = 1.65009
2023-04-10 18:49:00.892641 Epoch 21  	Train Loss = 1.52355 Val Loss = 1.63710
2023-04-10 18:49:12.916807 Epoch 22  	Train Loss = 1.52356 Val Loss = 1.64145
2023-04-10 18:49:24.933232 Epoch 23  	Train Loss = 1.51815 Val Loss = 1.63000
2023-04-10 18:49:37.038048 Epoch 24  	Train Loss = 1.51875 Val Loss = 1.62461
2023-04-10 18:49:49.127952 Epoch 25  	Train Loss = 1.51784 Val Loss = 1.66113
2023-04-10 18:50:01.001356 Epoch 26  	Train Loss = 1.51748 Val Loss = 1.62966
2023-04-10 18:50:13.014958 Epoch 27  	Train Loss = 1.51485 Val Loss = 1.62902
2023-04-10 18:50:25.181752 Epoch 28  	Train Loss = 1.51554 Val Loss = 1.63149
2023-04-10 18:50:37.313964 Epoch 29  	Train Loss = 1.51291 Val Loss = 1.61721
2023-04-10 18:50:49.541177 Epoch 30  	Train Loss = 1.51248 Val Loss = 1.62600
2023-04-10 18:51:01.608075 Epoch 31  	Train Loss = 1.51288 Val Loss = 1.64018
2023-04-10 18:51:13.475539 Epoch 32  	Train Loss = 1.51291 Val Loss = 1.63337
2023-04-10 18:51:25.525528 Epoch 33  	Train Loss = 1.51010 Val Loss = 1.62392
2023-04-10 18:51:36.823823 Epoch 34  	Train Loss = 1.51017 Val Loss = 1.62978
2023-04-10 18:51:48.868266 Epoch 35  	Train Loss = 1.50923 Val Loss = 1.64639
2023-04-10 18:52:00.839500 Epoch 36  	Train Loss = 1.50966 Val Loss = 1.62228
2023-04-10 18:52:12.897646 Epoch 37  	Train Loss = 1.50834 Val Loss = 1.61668
2023-04-10 18:52:24.949396 Epoch 38  	Train Loss = 1.50802 Val Loss = 1.64958
2023-04-10 18:52:36.995319 Epoch 39  	Train Loss = 1.50828 Val Loss = 1.63995
2023-04-10 18:52:49.078519 Epoch 40  	Train Loss = 1.50636 Val Loss = 1.62718
2023-04-10 18:53:01.170409 Epoch 41  	Train Loss = 1.50586 Val Loss = 1.62424
2023-04-10 18:53:12.963764 Epoch 42  	Train Loss = 1.50570 Val Loss = 1.62652
2023-04-10 18:53:25.034691 Epoch 43  	Train Loss = 1.50527 Val Loss = 1.62589
2023-04-10 18:53:35.988370 Epoch 44  	Train Loss = 1.50659 Val Loss = 1.63395
2023-04-10 18:53:47.295944 Epoch 45  	Train Loss = 1.50641 Val Loss = 1.61697
2023-04-10 18:53:59.101796 Epoch 46  	Train Loss = 1.50344 Val Loss = 1.62112
2023-04-10 18:54:11.102888 Epoch 47  	Train Loss = 1.50359 Val Loss = 1.62174
2023-04-10 18:54:23.023387 Epoch 48  	Train Loss = 1.50349 Val Loss = 1.63982
2023-04-10 18:54:35.050486 Epoch 49  	Train Loss = 1.50401 Val Loss = 1.61638
2023-04-10 18:54:47.034128 Epoch 50  	Train Loss = 1.50203 Val Loss = 1.63740
2023-04-10 18:54:58.993178 Epoch 51  	Train Loss = 1.48870 Val Loss = 1.61241
2023-04-10 18:55:11.527942 Epoch 52  	Train Loss = 1.48820 Val Loss = 1.60727
2023-04-10 18:55:22.801328 Epoch 53  	Train Loss = 1.48740 Val Loss = 1.60998
2023-04-10 18:55:34.318217 Epoch 54  	Train Loss = 1.48782 Val Loss = 1.61011
2023-04-10 18:55:46.456080 Epoch 55  	Train Loss = 1.48683 Val Loss = 1.59867
2023-04-10 18:55:58.064385 Epoch 56  	Train Loss = 1.48743 Val Loss = 1.60661
2023-04-10 18:56:09.864256 Epoch 57  	Train Loss = 1.48701 Val Loss = 1.61566
2023-04-10 18:56:21.823030 Epoch 58  	Train Loss = 1.48650 Val Loss = 1.60756
2023-04-10 18:56:33.882208 Epoch 59  	Train Loss = 1.48684 Val Loss = 1.60727
2023-04-10 18:56:45.748247 Epoch 60  	Train Loss = 1.48743 Val Loss = 1.61293
2023-04-10 18:56:57.650660 Epoch 61  	Train Loss = 1.48665 Val Loss = 1.61220
2023-04-10 18:57:09.524229 Epoch 62  	Train Loss = 1.48626 Val Loss = 1.60202
2023-04-10 18:57:21.362458 Epoch 63  	Train Loss = 1.48576 Val Loss = 1.60323
2023-04-10 18:57:33.088401 Epoch 64  	Train Loss = 1.48506 Val Loss = 1.60431
2023-04-10 18:57:45.021928 Epoch 65  	Train Loss = 1.48551 Val Loss = 1.60248
2023-04-10 18:57:56.951207 Epoch 66  	Train Loss = 1.48541 Val Loss = 1.60912
2023-04-10 18:58:08.786644 Epoch 67  	Train Loss = 1.48550 Val Loss = 1.60735
2023-04-10 18:58:20.782939 Epoch 68  	Train Loss = 1.48491 Val Loss = 1.60847
2023-04-10 18:58:31.921877 Epoch 69  	Train Loss = 1.48457 Val Loss = 1.60316
2023-04-10 18:58:43.804641 Epoch 70  	Train Loss = 1.48478 Val Loss = 1.60664
2023-04-10 18:58:55.659244 Epoch 71  	Train Loss = 1.48561 Val Loss = 1.60132
2023-04-10 18:59:07.582913 Epoch 72  	Train Loss = 1.48464 Val Loss = 1.60431
2023-04-10 18:59:19.452385 Epoch 73  	Train Loss = 1.48412 Val Loss = 1.60420
2023-04-10 18:59:31.341513 Epoch 74  	Train Loss = 1.48391 Val Loss = 1.61737
2023-04-10 18:59:43.271039 Epoch 75  	Train Loss = 1.48392 Val Loss = 1.60042
2023-04-10 18:59:55.568814 Epoch 76  	Train Loss = 1.48393 Val Loss = 1.59897
2023-04-10 19:00:07.563629 Epoch 77  	Train Loss = 1.48409 Val Loss = 1.60148
2023-04-10 19:00:19.456815 Epoch 78  	Train Loss = 1.48389 Val Loss = 1.60785
2023-04-10 19:00:31.380622 Epoch 79  	Train Loss = 1.48348 Val Loss = 1.60304
2023-04-10 19:00:43.354228 Epoch 80  	Train Loss = 1.48326 Val Loss = 1.60779
2023-04-10 19:00:55.170767 Epoch 81  	Train Loss = 1.47540 Val Loss = 1.59750
2023-04-10 19:01:06.922066 Epoch 82  	Train Loss = 1.47492 Val Loss = 1.59422
2023-04-10 19:01:19.001582 Epoch 83  	Train Loss = 1.47459 Val Loss = 1.60466
2023-04-10 19:01:30.895019 Epoch 84  	Train Loss = 1.47454 Val Loss = 1.59006
2023-04-10 19:01:42.916599 Epoch 85  	Train Loss = 1.47511 Val Loss = 1.59966
2023-04-10 19:01:54.875001 Epoch 86  	Train Loss = 1.47455 Val Loss = 1.59947
2023-04-10 19:02:06.917287 Epoch 87  	Train Loss = 1.47405 Val Loss = 1.61039
2023-04-10 19:02:18.797497 Epoch 88  	Train Loss = 1.47392 Val Loss = 1.60109
2023-04-10 19:02:30.763972 Epoch 89  	Train Loss = 1.47447 Val Loss = 1.59470
2023-04-10 19:02:42.684075 Epoch 90  	Train Loss = 1.47447 Val Loss = 1.59541
2023-04-10 19:02:54.673501 Epoch 91  	Train Loss = 1.47390 Val Loss = 1.59458
2023-04-10 19:03:06.658062 Epoch 92  	Train Loss = 1.47367 Val Loss = 1.59294
2023-04-10 19:03:18.506354 Epoch 93  	Train Loss = 1.47374 Val Loss = 1.59969
2023-04-10 19:03:30.442721 Epoch 94  	Train Loss = 1.47408 Val Loss = 1.59484
2023-04-10 19:03:42.270224 Epoch 95  	Train Loss = 1.47378 Val Loss = 1.59643
2023-04-10 19:03:54.022375 Epoch 96  	Train Loss = 1.47376 Val Loss = 1.60622
2023-04-10 19:04:05.922427 Epoch 97  	Train Loss = 1.47336 Val Loss = 1.59982
2023-04-10 19:04:17.865763 Epoch 98  	Train Loss = 1.47356 Val Loss = 1.59907
2023-04-10 19:04:29.809249 Epoch 99  	Train Loss = 1.47305 Val Loss = 1.59725
2023-04-10 19:04:41.678942 Epoch 100  	Train Loss = 1.47351 Val Loss = 1.59619
2023-04-10 19:04:53.744699 Epoch 101  	Train Loss = 1.47315 Val Loss = 1.59852
2023-04-10 19:05:05.805267 Epoch 102  	Train Loss = 1.47349 Val Loss = 1.60036
2023-04-10 19:05:17.908697 Epoch 103  	Train Loss = 1.47290 Val Loss = 1.61165
2023-04-10 19:05:29.822780 Epoch 104  	Train Loss = 1.47289 Val Loss = 1.59911
2023-04-10 19:05:41.812942 Epoch 105  	Train Loss = 1.47262 Val Loss = 1.59677
2023-04-10 19:05:53.759623 Epoch 106  	Train Loss = 1.47314 Val Loss = 1.59845
2023-04-10 19:06:05.679152 Epoch 107  	Train Loss = 1.47263 Val Loss = 1.59150
2023-04-10 19:06:17.937470 Epoch 108  	Train Loss = 1.47253 Val Loss = 1.59476
2023-04-10 19:06:29.957538 Epoch 109  	Train Loss = 1.47273 Val Loss = 1.59423
2023-04-10 19:06:41.868674 Epoch 110  	Train Loss = 1.47269 Val Loss = 1.59440
2023-04-10 19:06:53.841824 Epoch 111  	Train Loss = 1.47227 Val Loss = 1.59284
2023-04-10 19:07:05.711084 Epoch 112  	Train Loss = 1.47254 Val Loss = 1.59660
2023-04-10 19:07:17.562051 Epoch 113  	Train Loss = 1.47215 Val Loss = 1.59635
2023-04-10 19:07:29.533589 Epoch 114  	Train Loss = 1.47240 Val Loss = 1.60134
Early stopping at epoch: 114
Best at epoch 84:
Train Loss = 1.47454
Train RMSE = 3.25044, MAE = 1.44539, MAPE = 3.13747
Val Loss = 1.59006
Val RMSE = 3.69578, MAE = 1.59087, MAPE = 3.70544
--------- Test ---------
All Steps RMSE = 3.58930, MAE = 1.56337, MAPE = 3.54833
Step 1 RMSE = 1.56541, MAE = 0.85335, MAPE = 1.63751
Step 2 RMSE = 2.25290, MAE = 1.12499, MAPE = 2.27696
Step 3 RMSE = 2.77560, MAE = 1.30973, MAPE = 2.75945
Step 4 RMSE = 3.16877, MAE = 1.44541, MAPE = 3.14585
Step 5 RMSE = 3.46466, MAE = 1.54866, MAPE = 3.45746
Step 6 RMSE = 3.69361, MAE = 1.62960, MAPE = 3.71177
Step 7 RMSE = 3.87396, MAE = 1.69454, MAPE = 3.91824
Step 8 RMSE = 4.01604, MAE = 1.74829, MAPE = 4.08949
Step 9 RMSE = 4.12719, MAE = 1.79354, MAPE = 4.22848
Step 10 RMSE = 4.21888, MAE = 1.83325, MAPE = 4.34808
Step 11 RMSE = 4.30059, MAE = 1.86995, MAPE = 4.45117
Step 12 RMSE = 4.38355, MAE = 1.90909, MAPE = 4.55552
Inference time: 1.00 s
