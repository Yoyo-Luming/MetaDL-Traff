PEMS04
Trainset:	x-(10181, 12, 307, 3)	y-(10181, 12, 307, 1)
Valset:  	x-(3394, 12, 307, 3)  	y-(3394, 12, 307, 1)
Testset:	x-(3394, 12, 307, 3)	y-(3394, 12, 307, 1)

--------- STID ---------
{
    "num_nodes": 307,
    "in_steps": 12,
    "out_steps": 12,
    "train_size": 0.7,
    "val_size": 0.1,
    "time_of_day": true,
    "day_of_week": true,
    "lr": 0.002,
    "weight_decay": 0.0001,
    "milestones": [
        1,
        50,
        80
    ],
    "lr_decay_rate": 0.5,
    "batch_size": 32,
    "max_epochs": 200,
    "early_stop": 30,
    "use_cl": false,
    "model_args": {
        "num_nodes": 307,
        "input_len": 12,
        "output_len": 12,
        "input_dim": 3,
        "embed_dim": 32,
        "node_dim": 32,
        "temp_dim_tid": 32,
        "temp_dim_diw": 32,
        "time_of_day_size": 288,
        "day_of_week_size": 7,
        "if_node": true,
        "if_time_in_day": true,
        "if_day_in_week": true,
        "num_layer": 3
    }
}
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
STID                                     --                        --
├─Conv2d: 1-1                            [32, 32, 307, 1]          1,184
├─Sequential: 1-2                        [32, 128, 307, 1]         --
│    └─MultiLayerPerceptron: 2-1         [32, 128, 307, 1]         --
│    │    └─Conv2d: 3-1                  [32, 128, 307, 1]         16,512
│    │    └─ReLU: 3-2                    [32, 128, 307, 1]         --
│    │    └─Dropout: 3-3                 [32, 128, 307, 1]         --
│    │    └─Conv2d: 3-4                  [32, 128, 307, 1]         16,512
│    └─MultiLayerPerceptron: 2-2         [32, 128, 307, 1]         --
│    │    └─Conv2d: 3-5                  [32, 128, 307, 1]         16,512
│    │    └─ReLU: 3-6                    [32, 128, 307, 1]         --
│    │    └─Dropout: 3-7                 [32, 128, 307, 1]         --
│    │    └─Conv2d: 3-8                  [32, 128, 307, 1]         16,512
│    └─MultiLayerPerceptron: 2-3         [32, 128, 307, 1]         --
│    │    └─Conv2d: 3-9                  [32, 128, 307, 1]         16,512
│    │    └─ReLU: 3-10                   [32, 128, 307, 1]         --
│    │    └─Dropout: 3-11                [32, 128, 307, 1]         --
│    │    └─Conv2d: 3-12                 [32, 128, 307, 1]         16,512
├─Conv2d: 1-3                            [32, 12, 307, 1]          1,548
==========================================================================================
Total params: 101,804
Trainable params: 101,804
Non-trainable params: 0
Total mult-adds (G): 1.00
==========================================================================================
Input size (MB): 1.41
Forward/backward pass size (MB): 63.82
Params size (MB): 0.41
Estimated Total Size (MB): 65.64
==========================================================================================

Loss: HuberLoss

2023-04-10 20:20:31.641463 Epoch 1  	Train Loss = 28.73375 Val Loss = 22.60387
2023-04-10 20:20:36.599838 Epoch 2  	Train Loss = 21.21158 Val Loss = 21.12455
2023-04-10 20:20:41.611909 Epoch 3  	Train Loss = 20.49667 Val Loss = 20.85209
2023-04-10 20:20:46.659381 Epoch 4  	Train Loss = 19.91324 Val Loss = 20.56285
2023-04-10 20:20:51.712050 Epoch 5  	Train Loss = 19.55394 Val Loss = 20.09634
2023-04-10 20:20:56.719985 Epoch 6  	Train Loss = 19.27955 Val Loss = 19.73578
2023-04-10 20:21:01.914758 Epoch 7  	Train Loss = 19.06826 Val Loss = 19.69948
2023-04-10 20:21:07.470436 Epoch 8  	Train Loss = 18.95863 Val Loss = 19.31221
2023-04-10 20:21:13.291217 Epoch 9  	Train Loss = 18.82057 Val Loss = 19.11651
2023-04-10 20:21:19.028146 Epoch 10  	Train Loss = 18.70236 Val Loss = 19.01729
2023-04-10 20:21:24.743156 Epoch 11  	Train Loss = 18.62148 Val Loss = 18.99558
2023-04-10 20:21:30.384304 Epoch 12  	Train Loss = 18.53634 Val Loss = 18.73776
2023-04-10 20:21:36.185262 Epoch 13  	Train Loss = 18.41529 Val Loss = 18.82114
2023-04-10 20:21:41.902113 Epoch 14  	Train Loss = 18.30925 Val Loss = 18.69480
2023-04-10 20:21:47.590849 Epoch 15  	Train Loss = 18.31431 Val Loss = 18.67860
2023-04-10 20:21:53.373291 Epoch 16  	Train Loss = 18.27022 Val Loss = 18.48917
2023-04-10 20:21:59.148396 Epoch 17  	Train Loss = 18.16781 Val Loss = 18.78696
2023-04-10 20:22:04.867638 Epoch 18  	Train Loss = 18.10854 Val Loss = 18.60511
2023-04-10 20:22:10.559549 Epoch 19  	Train Loss = 18.04669 Val Loss = 18.43901
2023-04-10 20:22:16.299785 Epoch 20  	Train Loss = 18.04728 Val Loss = 18.42615
2023-04-10 20:22:22.183147 Epoch 21  	Train Loss = 18.03088 Val Loss = 18.40504
2023-04-10 20:22:27.998696 Epoch 22  	Train Loss = 17.96325 Val Loss = 18.31527
2023-04-10 20:22:33.854730 Epoch 23  	Train Loss = 17.96654 Val Loss = 18.34671
2023-04-10 20:22:39.597350 Epoch 24  	Train Loss = 17.93936 Val Loss = 18.36646
2023-04-10 20:22:45.348801 Epoch 25  	Train Loss = 17.89655 Val Loss = 18.50510
2023-04-10 20:22:51.032468 Epoch 26  	Train Loss = 17.87366 Val Loss = 18.36021
2023-04-10 20:22:56.777862 Epoch 27  	Train Loss = 17.85516 Val Loss = 18.15487
2023-04-10 20:23:02.589989 Epoch 28  	Train Loss = 17.79619 Val Loss = 18.61371
2023-04-10 20:23:08.427952 Epoch 29  	Train Loss = 17.83463 Val Loss = 18.53776
2023-04-10 20:23:14.182987 Epoch 30  	Train Loss = 17.77794 Val Loss = 18.35668
2023-04-10 20:23:19.911115 Epoch 31  	Train Loss = 17.83110 Val Loss = 18.20337
2023-04-10 20:23:25.571739 Epoch 32  	Train Loss = 17.75659 Val Loss = 18.16750
2023-04-10 20:23:30.546351 Epoch 33  	Train Loss = 17.72920 Val Loss = 18.29802
2023-04-10 20:23:36.145400 Epoch 34  	Train Loss = 17.70335 Val Loss = 18.14135
2023-04-10 20:23:41.848390 Epoch 35  	Train Loss = 17.73626 Val Loss = 18.59917
2023-04-10 20:23:47.621227 Epoch 36  	Train Loss = 17.71897 Val Loss = 18.07413
2023-04-10 20:23:53.455379 Epoch 37  	Train Loss = 17.63727 Val Loss = 18.34263
2023-04-10 20:23:59.276230 Epoch 38  	Train Loss = 17.66440 Val Loss = 18.49090
2023-04-10 20:24:05.136935 Epoch 39  	Train Loss = 17.64684 Val Loss = 18.47909
2023-04-10 20:24:10.927318 Epoch 40  	Train Loss = 17.66370 Val Loss = 18.13836
2023-04-10 20:24:16.685257 Epoch 41  	Train Loss = 17.63374 Val Loss = 18.35440
2023-04-10 20:24:22.466555 Epoch 42  	Train Loss = 17.59517 Val Loss = 18.33351
2023-04-10 20:24:28.142593 Epoch 43  	Train Loss = 17.57573 Val Loss = 18.10874
2023-04-10 20:24:33.838439 Epoch 44  	Train Loss = 17.56753 Val Loss = 18.12822
2023-04-10 20:24:39.733804 Epoch 45  	Train Loss = 17.59333 Val Loss = 18.61228
2023-04-10 20:24:46.003179 Epoch 46  	Train Loss = 17.56878 Val Loss = 18.36464
2023-04-10 20:24:51.670960 Epoch 47  	Train Loss = 17.62158 Val Loss = 18.02739
2023-04-10 20:24:57.479700 Epoch 48  	Train Loss = 17.57049 Val Loss = 18.12541
2023-04-10 20:25:03.421355 Epoch 49  	Train Loss = 17.57241 Val Loss = 18.02799
2023-04-10 20:25:09.288192 Epoch 50  	Train Loss = 17.55866 Val Loss = 18.16775
2023-04-10 20:25:15.004261 Epoch 51  	Train Loss = 17.35277 Val Loss = 17.94339
2023-04-10 20:25:20.844986 Epoch 52  	Train Loss = 17.36143 Val Loss = 18.19097
2023-04-10 20:25:26.602988 Epoch 53  	Train Loss = 17.35291 Val Loss = 17.93717
2023-04-10 20:25:32.332590 Epoch 54  	Train Loss = 17.34216 Val Loss = 18.03744
2023-04-10 20:25:38.077951 Epoch 55  	Train Loss = 17.35884 Val Loss = 18.15022
2023-04-10 20:25:43.779718 Epoch 56  	Train Loss = 17.34135 Val Loss = 17.97183
2023-04-10 20:25:49.667479 Epoch 57  	Train Loss = 17.33287 Val Loss = 18.09647
2023-04-10 20:25:55.445167 Epoch 58  	Train Loss = 17.32163 Val Loss = 18.10764
2023-04-10 20:26:01.164495 Epoch 59  	Train Loss = 17.33386 Val Loss = 18.08350
2023-04-10 20:26:07.095761 Epoch 60  	Train Loss = 17.34375 Val Loss = 18.05521
2023-04-10 20:26:12.855287 Epoch 61  	Train Loss = 17.33708 Val Loss = 18.04074
2023-04-10 20:26:18.613337 Epoch 62  	Train Loss = 17.32289 Val Loss = 17.89476
2023-04-10 20:26:24.329883 Epoch 63  	Train Loss = 17.32621 Val Loss = 17.95157
2023-04-10 20:26:29.974776 Epoch 64  	Train Loss = 17.30397 Val Loss = 17.91941
2023-04-10 20:26:35.739271 Epoch 65  	Train Loss = 17.32247 Val Loss = 17.97854
2023-04-10 20:26:41.830486 Epoch 66  	Train Loss = 17.31241 Val Loss = 17.87323
2023-04-10 20:26:47.916919 Epoch 67  	Train Loss = 17.32257 Val Loss = 18.14841
2023-04-10 20:26:54.058714 Epoch 68  	Train Loss = 17.30417 Val Loss = 18.04525
2023-04-10 20:27:00.322204 Epoch 69  	Train Loss = 17.31342 Val Loss = 17.94822
2023-04-10 20:27:06.499904 Epoch 70  	Train Loss = 17.29070 Val Loss = 18.02344
2023-04-10 20:27:12.333819 Epoch 71  	Train Loss = 17.30489 Val Loss = 17.99370
2023-04-10 20:27:18.359987 Epoch 72  	Train Loss = 17.27819 Val Loss = 17.91507
2023-04-10 20:27:24.129109 Epoch 73  	Train Loss = 17.28182 Val Loss = 17.91247
2023-04-10 20:27:29.909782 Epoch 74  	Train Loss = 17.28674 Val Loss = 17.86584
2023-04-10 20:27:35.729750 Epoch 75  	Train Loss = 17.28262 Val Loss = 17.97466
2023-04-10 20:27:41.513166 Epoch 76  	Train Loss = 17.30001 Val Loss = 18.02377
2023-04-10 20:27:47.360485 Epoch 77  	Train Loss = 17.26791 Val Loss = 18.01886
2023-04-10 20:27:53.073912 Epoch 78  	Train Loss = 17.29000 Val Loss = 17.81612
2023-04-10 20:27:58.898920 Epoch 79  	Train Loss = 17.25159 Val Loss = 18.02341
2023-04-10 20:28:04.842016 Epoch 80  	Train Loss = 17.26664 Val Loss = 17.93767
2023-04-10 20:28:10.532163 Epoch 81  	Train Loss = 17.18166 Val Loss = 17.87567
2023-04-10 20:28:16.402584 Epoch 82  	Train Loss = 17.17050 Val Loss = 17.96160
2023-04-10 20:28:22.173276 Epoch 83  	Train Loss = 17.16350 Val Loss = 17.91534
2023-04-10 20:28:27.833487 Epoch 84  	Train Loss = 17.17185 Val Loss = 17.88436
2023-04-10 20:28:33.594315 Epoch 85  	Train Loss = 17.18457 Val Loss = 17.84883
2023-04-10 20:28:39.380908 Epoch 86  	Train Loss = 17.16584 Val Loss = 18.06486
2023-04-10 20:28:44.740400 Epoch 87  	Train Loss = 17.17199 Val Loss = 17.84942
2023-04-10 20:28:47.838091 Epoch 88  	Train Loss = 17.16326 Val Loss = 17.95622
2023-04-10 20:28:50.376399 Epoch 89  	Train Loss = 17.14752 Val Loss = 17.84761
2023-04-10 20:28:52.803053 Epoch 90  	Train Loss = 17.17882 Val Loss = 17.94748
2023-04-10 20:28:55.218107 Epoch 91  	Train Loss = 17.16747 Val Loss = 17.82925
2023-04-10 20:28:57.638569 Epoch 92  	Train Loss = 17.15238 Val Loss = 17.93555
2023-04-10 20:29:00.056340 Epoch 93  	Train Loss = 17.16607 Val Loss = 17.94077
2023-04-10 20:29:02.477375 Epoch 94  	Train Loss = 17.16357 Val Loss = 18.02034
2023-04-10 20:29:04.896393 Epoch 95  	Train Loss = 17.16416 Val Loss = 17.90601
2023-04-10 20:29:07.311604 Epoch 96  	Train Loss = 17.14364 Val Loss = 17.95129
2023-04-10 20:29:09.722957 Epoch 97  	Train Loss = 17.13957 Val Loss = 17.89222
2023-04-10 20:29:12.140363 Epoch 98  	Train Loss = 17.15323 Val Loss = 17.88625
2023-04-10 20:29:14.560011 Epoch 99  	Train Loss = 17.14565 Val Loss = 17.89627
2023-04-10 20:29:16.975440 Epoch 100  	Train Loss = 17.14992 Val Loss = 17.93265
2023-04-10 20:29:19.391161 Epoch 101  	Train Loss = 17.14010 Val Loss = 17.86254
2023-04-10 20:29:21.809799 Epoch 102  	Train Loss = 17.14093 Val Loss = 17.84308
2023-04-10 20:29:24.231317 Epoch 103  	Train Loss = 17.14731 Val Loss = 17.90939
2023-04-10 20:29:26.648160 Epoch 104  	Train Loss = 17.13509 Val Loss = 17.89619
2023-04-10 20:29:29.062944 Epoch 105  	Train Loss = 17.14003 Val Loss = 17.87560
2023-04-10 20:29:31.474517 Epoch 106  	Train Loss = 17.14878 Val Loss = 17.93349
2023-04-10 20:29:33.892583 Epoch 107  	Train Loss = 17.15009 Val Loss = 17.88421
2023-04-10 20:29:36.304737 Epoch 108  	Train Loss = 17.15574 Val Loss = 17.94998
Early stopping at epoch: 108
Best at epoch 78:
Train Loss = 17.29000
Train RMSE = 28.72442, MAE = 17.41414, MAPE = 12.67413
Val Loss = 17.81612
Val RMSE = 30.72307, MAE = 18.67252, MAPE = 12.14577
--------- Test ---------
All Steps RMSE = 30.08761, MAE = 18.54265, MAPE = 12.31482
Step 1 RMSE = 26.98764, MAE = 16.76895, MAPE = 11.12392
Step 2 RMSE = 27.92596, MAE = 17.26947, MAPE = 11.44334
Step 3 RMSE = 28.67716, MAE = 17.71452, MAPE = 11.68144
Step 4 RMSE = 29.25967, MAE = 18.05437, MAPE = 11.90707
Step 5 RMSE = 29.70433, MAE = 18.30909, MAPE = 12.04841
Step 6 RMSE = 30.09155, MAE = 18.53060, MAPE = 12.29285
Step 7 RMSE = 30.48481, MAE = 18.77135, MAPE = 12.47453
Step 8 RMSE = 30.82308, MAE = 18.97510, MAPE = 12.64563
Step 9 RMSE = 31.14135, MAE = 19.15955, MAPE = 12.77393
Step 10 RMSE = 31.46955, MAE = 19.39008, MAPE = 12.88782
Step 11 RMSE = 31.78533, MAE = 19.61021, MAPE = 13.11921
Step 12 RMSE = 32.23036, MAE = 19.95838, MAPE = 13.37932
Inference time: 0.32 s
