PEMSBAY
Trainset:	x-(36465, 12, 325, 3)	y-(36465, 12, 325, 1)
Valset:  	x-(5209, 12, 325, 3)  	y-(5209, 12, 325, 1)
Testset:	x-(10419, 12, 325, 3)	y-(10419, 12, 325, 1)

--------- STMetaLSTM ---------
{
    "num_nodes": 325,
    "in_steps": 12,
    "out_steps": 12,
    "time_of_day": true,
    "day_of_week": true,
    "lr": 0.001,
    "weight_decay": 0,
    "milestones": [
        10,
        40
    ],
    "clip_grad": false,
    "batch_size": 64,
    "max_epochs": 200,
    "use_cl": false,
    "pass_device": true,
    "model_args": {
        "num_nodes": 325,
        "node_emb_file": "../data/PEMSBAY/spatial_embeddings.npz",
        "in_steps": 12,
        "out_steps": 12,
        "input_dim": 1,
        "output_dim": 1,
        "lstm_hidden_dim": 32,
        "tod_embedding_dim": 24,
        "dow_embedding_dim": 7,
        "node_embedding_dim": 64,
        "learner_hidden_dim": 128,
        "z_dim": 32,
        "num_layers": 1,
        "seq2seq": false,
        "device": "cuda:0"
    }
}
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
STMetaLSTM                               [64, 12, 325, 1]          20,800
├─Sequential: 1-1                        [64, 325, 32]             --
│    └─Linear: 2-1                       [64, 325, 32]             416
│    └─Tanh: 2-2                         [64, 325, 32]             --
│    └─Linear: 2-3                       [64, 325, 32]             1,056
│    └─Tanh: 2-4                         [64, 325, 32]             --
│    └─Linear: 2-5                       [64, 325, 32]             1,056
├─Sequential: 1-2                        [64, 325, 32]             --
│    └─Linear: 2-6                       [64, 325, 32]             416
│    └─Tanh: 2-7                         [64, 325, 32]             --
│    └─Linear: 2-8                       [64, 325, 32]             1,056
│    └─Tanh: 2-9                         [64, 325, 32]             --
│    └─Linear: 2-10                      [64, 325, 32]             1,056
├─ModuleList: 1-3                        --                        --
│    └─STMetaLSTMEncoder: 2-11           [64, 12, 325, 32]         --
│    │    └─Sequential: 3-1              [64, 325, 128]            32,896
│    │    └─Sequential: 3-2              [64, 325, 4096]           544,768
│    │    └─Sequential: 3-3              [64, 325, 128]            32,896
│    │    └─STMetaLSTMCell: 3-4          [64, 325, 32]             --
│    │    └─STMetaLSTMCell: 3-5          [64, 325, 32]             --
│    │    └─STMetaLSTMCell: 3-6          [64, 325, 32]             --
│    │    └─STMetaLSTMCell: 3-7          [64, 325, 32]             --
│    │    └─STMetaLSTMCell: 3-8          [64, 325, 32]             --
│    │    └─STMetaLSTMCell: 3-9          [64, 325, 32]             --
│    │    └─STMetaLSTMCell: 3-10         [64, 325, 32]             --
│    │    └─STMetaLSTMCell: 3-11         [64, 325, 32]             --
│    │    └─STMetaLSTMCell: 3-12         [64, 325, 32]             --
│    │    └─STMetaLSTMCell: 3-13         [64, 325, 32]             --
│    │    └─STMetaLSTMCell: 3-14         [64, 325, 32]             --
│    │    └─STMetaLSTMCell: 3-15         [64, 325, 32]             --
├─Linear: 1-4                            [64, 325, 12]             396
==========================================================================================
Total params: 636,812
Trainable params: 636,812
Non-trainable params: 0
Total mult-adds (M): 39.42
==========================================================================================
Input size (MB): 3.00
Forward/backward pass size (MB): 822.02
Params size (MB): 2.46
Estimated Total Size (MB): 827.48
==========================================================================================

Loss: MaskedMAELoss

2023-04-16 19:41:11.193108 Epoch 1  	Train Loss = 2.14028 Val Loss = 1.98357
2023-04-16 19:41:50.519875 Epoch 2  	Train Loss = 1.73674 Val Loss = 1.85129
2023-04-16 19:42:29.838572 Epoch 3  	Train Loss = 1.67005 Val Loss = 1.81196
2023-04-16 19:43:09.415912 Epoch 4  	Train Loss = 1.63704 Val Loss = 1.77128
2023-04-16 19:43:49.122464 Epoch 5  	Train Loss = 1.61345 Val Loss = 1.76432
2023-04-16 19:44:28.784908 Epoch 6  	Train Loss = 1.59694 Val Loss = 1.73096
2023-04-16 19:45:08.557364 Epoch 7  	Train Loss = 1.58549 Val Loss = 1.73617
2023-04-16 19:45:48.366733 Epoch 8  	Train Loss = 1.57259 Val Loss = 1.72243
2023-04-16 19:46:28.161990 Epoch 9  	Train Loss = 1.56296 Val Loss = 1.70878
2023-04-16 19:47:07.585182 Epoch 10  	Train Loss = 1.55555 Val Loss = 1.71832
2023-04-16 19:47:47.120602 Epoch 11  	Train Loss = 1.52743 Val Loss = 1.68139
2023-04-16 19:48:26.696781 Epoch 12  	Train Loss = 1.52217 Val Loss = 1.68173
2023-04-16 19:49:06.169051 Epoch 13  	Train Loss = 1.51934 Val Loss = 1.68243
2023-04-16 19:49:45.604134 Epoch 14  	Train Loss = 1.51744 Val Loss = 1.68243
2023-04-16 19:50:24.991329 Epoch 15  	Train Loss = 1.51582 Val Loss = 1.68241
2023-04-16 19:51:04.700502 Epoch 16  	Train Loss = 1.51383 Val Loss = 1.68171
2023-04-16 19:51:44.346729 Epoch 17  	Train Loss = 1.51193 Val Loss = 1.67961
2023-04-16 19:52:23.902712 Epoch 18  	Train Loss = 1.51057 Val Loss = 1.67856
2023-04-16 19:53:03.414762 Epoch 19  	Train Loss = 1.50900 Val Loss = 1.68144
2023-04-16 19:53:42.933915 Epoch 20  	Train Loss = 1.50779 Val Loss = 1.68009
2023-04-16 19:54:22.461699 Epoch 21  	Train Loss = 1.50637 Val Loss = 1.68176
2023-04-16 19:55:01.979456 Epoch 22  	Train Loss = 1.50498 Val Loss = 1.67807
2023-04-16 19:55:41.522409 Epoch 23  	Train Loss = 1.50374 Val Loss = 1.67692
2023-04-16 19:56:20.914656 Epoch 24  	Train Loss = 1.50223 Val Loss = 1.68308
2023-04-16 19:57:00.562824 Epoch 25  	Train Loss = 1.50142 Val Loss = 1.67654
2023-04-16 19:57:40.261978 Epoch 26  	Train Loss = 1.49995 Val Loss = 1.67459
2023-04-16 19:58:19.979777 Epoch 27  	Train Loss = 1.49902 Val Loss = 1.67833
2023-04-16 19:58:59.720594 Epoch 28  	Train Loss = 1.49790 Val Loss = 1.67428
2023-04-16 19:59:39.419067 Epoch 29  	Train Loss = 1.49690 Val Loss = 1.68057
2023-04-16 20:00:19.133053 Epoch 30  	Train Loss = 1.49560 Val Loss = 1.67940
2023-04-16 20:00:58.835752 Epoch 31  	Train Loss = 1.49470 Val Loss = 1.68007
2023-04-16 20:01:38.444724 Epoch 32  	Train Loss = 1.49349 Val Loss = 1.68273
2023-04-16 20:02:18.099916 Epoch 33  	Train Loss = 1.49240 Val Loss = 1.67402
2023-04-16 20:02:57.781530 Epoch 34  	Train Loss = 1.49114 Val Loss = 1.67613
2023-04-16 20:03:37.430265 Epoch 35  	Train Loss = 1.49077 Val Loss = 1.67436
2023-04-16 20:04:17.084609 Epoch 36  	Train Loss = 1.48955 Val Loss = 1.67575
2023-04-16 20:04:56.846684 Epoch 37  	Train Loss = 1.48839 Val Loss = 1.67655
2023-04-16 20:05:36.448698 Epoch 38  	Train Loss = 1.48726 Val Loss = 1.67600
2023-04-16 20:06:15.980427 Epoch 39  	Train Loss = 1.48625 Val Loss = 1.67556
2023-04-16 20:06:55.495766 Epoch 40  	Train Loss = 1.48519 Val Loss = 1.67903
2023-04-16 20:07:34.985862 Epoch 41  	Train Loss = 1.48120 Val Loss = 1.67323
2023-04-16 20:08:14.465269 Epoch 42  	Train Loss = 1.48034 Val Loss = 1.67406
2023-04-16 20:08:53.957454 Epoch 43  	Train Loss = 1.48018 Val Loss = 1.67468
2023-04-16 20:09:33.483262 Epoch 44  	Train Loss = 1.48009 Val Loss = 1.67314
2023-04-16 20:10:13.030209 Epoch 45  	Train Loss = 1.47965 Val Loss = 1.67452
2023-04-16 20:10:52.595481 Epoch 46  	Train Loss = 1.47947 Val Loss = 1.67343
2023-04-16 20:11:32.152747 Epoch 47  	Train Loss = 1.47927 Val Loss = 1.67365
2023-04-16 20:12:11.739739 Epoch 48  	Train Loss = 1.47925 Val Loss = 1.67409
2023-04-16 20:12:51.356546 Epoch 49  	Train Loss = 1.47903 Val Loss = 1.67494
2023-04-16 20:13:30.918510 Epoch 50  	Train Loss = 1.47905 Val Loss = 1.67573
2023-04-16 20:14:10.493331 Epoch 51  	Train Loss = 1.47880 Val Loss = 1.67339
2023-04-16 20:14:50.056841 Epoch 52  	Train Loss = 1.47859 Val Loss = 1.67537
2023-04-16 20:15:29.589308 Epoch 53  	Train Loss = 1.47846 Val Loss = 1.67352
2023-04-16 20:16:09.138125 Epoch 54  	Train Loss = 1.47846 Val Loss = 1.67373
Early stopping at epoch: 54
Best at epoch 44:
Train Loss = 1.48009
Train RMSE = 3.35410, MAE = 1.47789, MAPE = 3.20578
Val Loss = 1.67314
Val RMSE = 3.92040, MAE = 1.66234, MAPE = 3.88865
--------- Test ---------
All Steps RMSE = 3.83532, MAE = 1.63453, MAPE = 3.73469
Step 1 RMSE = 1.61303, MAE = 0.88143, MAPE = 1.73042
Step 2 RMSE = 2.31825, MAE = 1.15230, MAPE = 2.35766
Step 3 RMSE = 2.88170, MAE = 1.34864, MAPE = 2.86505
Step 4 RMSE = 3.32177, MAE = 1.49792, MAPE = 3.28713
Step 5 RMSE = 3.66733, MAE = 1.61380, MAPE = 3.63235
Step 6 RMSE = 3.93816, MAE = 1.70578, MAPE = 3.91097
Step 7 RMSE = 4.14613, MAE = 1.77968, MAPE = 4.13745
Step 8 RMSE = 4.30605, MAE = 1.83911, MAPE = 4.32078
Step 9 RMSE = 4.43567, MAE = 1.88799, MAPE = 4.47053
Step 10 RMSE = 4.54709, MAE = 1.93043, MAPE = 4.59519
Step 11 RMSE = 4.64965, MAE = 1.96940, MAPE = 4.70345
Step 12 RMSE = 4.74763, MAE = 2.00793, MAPE = 4.80527
Inference time: 3.49 s
