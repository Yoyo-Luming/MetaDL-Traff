METRLA
Trainset:	x-(23974, 12, 207, 3)	y-(23974, 12, 207, 1)
Valset:  	x-(3425, 12, 207, 3)  	y-(3425, 12, 207, 1)
Testset:	x-(6850, 12, 207, 3)	y-(6850, 12, 207, 1)

--------- STMetaLSTM ---------
{
    "num_nodes": 207,
    "in_steps": 12,
    "out_steps": 12,
    "time_of_day": true,
    "day_of_week": true,
    "lr": 0.001,
    "weight_decay": 0,
    "milestones": [
        10,
        40
    ],
    "clip_grad": false,
    "batch_size": 64,
    "max_epochs": 200,
    "use_cl": false,
    "pass_device": true,
    "model_args": {
        "num_nodes": 207,
        "node_emb_file": "../data/METRLA/spatial_embeddings.npz",
        "in_steps": 12,
        "out_steps": 12,
        "input_dim": 1,
        "output_dim": 1,
        "lstm_hidden_dim": 32,
        "tod_embedding_dim": 24,
        "dow_embedding_dim": 7,
        "node_embedding_dim": 64,
        "learner_hidden_dim": 128,
        "z_dim": 32,
        "num_layers": 1,
        "seq2seq": false,
        "device": "cuda:0"
    }
}
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
STMetaLSTM                               [64, 12, 207, 1]          13,248
├─Sequential: 1-1                        [64, 207, 32]             --
│    └─Linear: 2-1                       [64, 207, 32]             416
│    └─Tanh: 2-2                         [64, 207, 32]             --
│    └─Linear: 2-3                       [64, 207, 32]             1,056
│    └─Tanh: 2-4                         [64, 207, 32]             --
│    └─Linear: 2-5                       [64, 207, 32]             1,056
├─Sequential: 1-2                        [64, 207, 32]             --
│    └─Linear: 2-6                       [64, 207, 32]             416
│    └─Tanh: 2-7                         [64, 207, 32]             --
│    └─Linear: 2-8                       [64, 207, 32]             1,056
│    └─Tanh: 2-9                         [64, 207, 32]             --
│    └─Linear: 2-10                      [64, 207, 32]             1,056
├─ModuleList: 1-3                        --                        --
│    └─STMetaLSTMEncoder: 2-11           [64, 12, 207, 32]         --
│    │    └─Sequential: 3-1              [64, 207, 128]            32,896
│    │    └─Sequential: 3-2              [64, 207, 4096]           544,768
│    │    └─Sequential: 3-3              [64, 207, 128]            32,896
│    │    └─STMetaLSTMCell: 3-4          [64, 207, 32]             --
│    │    └─STMetaLSTMCell: 3-5          [64, 207, 32]             --
│    │    └─STMetaLSTMCell: 3-6          [64, 207, 32]             --
│    │    └─STMetaLSTMCell: 3-7          [64, 207, 32]             --
│    │    └─STMetaLSTMCell: 3-8          [64, 207, 32]             --
│    │    └─STMetaLSTMCell: 3-9          [64, 207, 32]             --
│    │    └─STMetaLSTMCell: 3-10         [64, 207, 32]             --
│    │    └─STMetaLSTMCell: 3-11         [64, 207, 32]             --
│    │    └─STMetaLSTMCell: 3-12         [64, 207, 32]             --
│    │    └─STMetaLSTMCell: 3-13         [64, 207, 32]             --
│    │    └─STMetaLSTMCell: 3-14         [64, 207, 32]             --
│    │    └─STMetaLSTMCell: 3-15         [64, 207, 32]             --
├─Linear: 1-4                            [64, 207, 12]             396
==========================================================================================
Total params: 629,260
Trainable params: 629,260
Non-trainable params: 0
Total mult-adds (M): 39.42
==========================================================================================
Input size (MB): 1.91
Forward/backward pass size (MB): 523.56
Params size (MB): 2.46
Estimated Total Size (MB): 527.93
==========================================================================================

Loss: MaskedMAELoss

2023-04-16 11:05:17.046418 Epoch 1  	Train Loss = 3.97763 Val Loss = 3.29800
2023-04-16 11:05:34.170722 Epoch 2  	Train Loss = 3.37120 Val Loss = 3.16771
2023-04-16 11:05:51.247281 Epoch 3  	Train Loss = 3.24956 Val Loss = 3.10930
2023-04-16 11:06:08.328509 Epoch 4  	Train Loss = 3.17362 Val Loss = 3.08023
2023-04-16 11:06:25.438212 Epoch 5  	Train Loss = 3.12076 Val Loss = 3.03447
2023-04-16 11:06:42.528656 Epoch 6  	Train Loss = 3.08735 Val Loss = 3.01172
2023-04-16 11:06:59.614896 Epoch 7  	Train Loss = 3.05835 Val Loss = 3.03452
2023-04-16 11:07:16.737537 Epoch 8  	Train Loss = 3.04386 Val Loss = 2.99845
2023-04-16 11:07:33.854079 Epoch 9  	Train Loss = 3.02088 Val Loss = 2.98898
2023-04-16 11:07:50.932055 Epoch 10  	Train Loss = 3.00658 Val Loss = 3.01584
2023-04-16 11:08:08.023021 Epoch 11  	Train Loss = 2.96186 Val Loss = 2.97653
2023-04-16 11:08:25.141856 Epoch 12  	Train Loss = 2.95164 Val Loss = 2.97718
2023-04-16 11:08:42.270842 Epoch 13  	Train Loss = 2.94816 Val Loss = 2.97363
2023-04-16 11:08:59.419287 Epoch 14  	Train Loss = 2.94394 Val Loss = 2.96701
2023-04-16 11:09:16.546725 Epoch 15  	Train Loss = 2.94126 Val Loss = 2.96241
2023-04-16 11:09:33.630570 Epoch 16  	Train Loss = 2.93830 Val Loss = 2.96366
2023-04-16 11:09:50.764299 Epoch 17  	Train Loss = 2.93521 Val Loss = 2.97954
2023-04-16 11:10:07.930389 Epoch 18  	Train Loss = 2.93289 Val Loss = 2.96327
2023-04-16 11:10:25.018862 Epoch 19  	Train Loss = 2.92976 Val Loss = 2.96781
2023-04-16 11:10:42.151172 Epoch 20  	Train Loss = 2.92686 Val Loss = 2.97072
2023-04-16 11:10:59.271187 Epoch 21  	Train Loss = 2.92366 Val Loss = 2.96792
2023-04-16 11:11:16.435462 Epoch 22  	Train Loss = 2.92157 Val Loss = 2.96555
2023-04-16 11:11:33.540170 Epoch 23  	Train Loss = 2.91934 Val Loss = 2.96493
2023-04-16 11:11:50.618862 Epoch 24  	Train Loss = 2.91742 Val Loss = 2.96952
2023-04-16 11:12:07.746265 Epoch 25  	Train Loss = 2.91461 Val Loss = 2.96539
Early stopping at epoch: 25
Best at epoch 15:
Train Loss = 2.94126
Train RMSE = 5.96913, MAE = 2.91031, MAPE = 7.91060
Val Loss = 2.96241
Val RMSE = 6.37214, MAE = 3.01268, MAPE = 8.66603
--------- Test ---------
All Steps RMSE = 6.64946, MAE = 3.20716, MAPE = 9.29368
Step 1 RMSE = 4.16303, MAE = 2.35029, MAPE = 5.89116
Step 2 RMSE = 5.04622, MAE = 2.64784, MAPE = 6.96442
Step 3 RMSE = 5.64212, MAE = 2.85466, MAPE = 7.79595
Step 4 RMSE = 6.11510, MAE = 3.02243, MAPE = 8.49398
Step 5 RMSE = 6.48095, MAE = 3.15169, MAPE = 9.02635
Step 6 RMSE = 6.79089, MAE = 3.26618, MAPE = 9.53517
Step 7 RMSE = 7.01998, MAE = 3.36234, MAPE = 9.94391
Step 8 RMSE = 7.21321, MAE = 3.44436, MAPE = 10.28604
Step 9 RMSE = 7.36830, MAE = 3.51303, MAPE = 10.56294
Step 10 RMSE = 7.51592, MAE = 3.57368, MAPE = 10.81962
Step 11 RMSE = 7.63528, MAE = 3.62413, MAPE = 11.01186
Step 12 RMSE = 7.74958, MAE = 3.67538, MAPE = 11.19302
Inference time: 1.50 s
