METRLA
Trainset:	x-(23974, 12, 207, 3)	y-(23974, 12, 207, 1)
Valset:  	x-(3425, 12, 207, 3)  	y-(3425, 12, 207, 1)
Testset:	x-(6850, 12, 207, 3)	y-(6850, 12, 207, 1)

--------- STMetaGRU ---------
{
    "num_nodes": 207,
    "in_steps": 12,
    "out_steps": 12,
    "time_of_day": true,
    "day_of_week": true,
    "lr": 0.001,
    "weight_decay": 0,
    "milestones": [
        10,
        40
    ],
    "clip_grad": false,
    "batch_size": 64,
    "max_epochs": 200,
    "use_cl": false,
    "pass_device": true,
    "model_args": {
        "num_nodes": 207,
        "node_emb_file": "../data/METRLA/spatial_embeddings.npz",
        "in_steps": 12,
        "out_steps": 12,
        "input_dim": 1,
        "output_dim": 1,
        "gru_hidden_dim": 32,
        "tod_embedding_dim": 24,
        "dow_embedding_dim": 7,
        "node_embedding_dim": 64,
        "learner_hidden_dim": 128,
        "z_dim": 32,
        "num_layers": 1,
        "seq2seq": false,
        "device": "cuda:0"
    }
}
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
STMetaGRU                                [64, 12, 207, 1]          13,248
├─Sequential: 1-1                        [64, 207, 32]             --
│    └─Linear: 2-1                       [64, 207, 32]             416
│    └─Tanh: 2-2                         [64, 207, 32]             --
│    └─Linear: 2-3                       [64, 207, 32]             1,056
│    └─Tanh: 2-4                         [64, 207, 32]             --
│    └─Linear: 2-5                       [64, 207, 32]             1,056
├─Sequential: 1-2                        [64, 207, 32]             --
│    └─Linear: 2-6                       [64, 207, 32]             416
│    └─Tanh: 2-7                         [64, 207, 32]             --
│    └─Linear: 2-8                       [64, 207, 32]             1,056
│    └─Tanh: 2-9                         [64, 207, 32]             --
│    └─Linear: 2-10                      [64, 207, 32]             1,056
├─ModuleList: 1-3                        --                        --
│    └─STMetaGRUEncoder: 2-11            [64, 12, 207, 32]         --
│    │    └─Sequential: 3-1              [64, 207, 96]             28,768
│    │    └─Sequential: 3-2              [64, 207, 3072]           412,672
│    │    └─Sequential: 3-3              [64, 207, 96]             28,768
│    │    └─STMetaGRUCell: 3-4           [64, 207, 1, 32]          --
│    │    └─STMetaGRUCell: 3-5           [64, 207, 1, 32]          --
│    │    └─STMetaGRUCell: 3-6           [64, 207, 1, 32]          --
│    │    └─STMetaGRUCell: 3-7           [64, 207, 1, 32]          --
│    │    └─STMetaGRUCell: 3-8           [64, 207, 1, 32]          --
│    │    └─STMetaGRUCell: 3-9           [64, 207, 1, 32]          --
│    │    └─STMetaGRUCell: 3-10          [64, 207, 1, 32]          --
│    │    └─STMetaGRUCell: 3-11          [64, 207, 1, 32]          --
│    │    └─STMetaGRUCell: 3-12          [64, 207, 1, 32]          --
│    │    └─STMetaGRUCell: 3-13          [64, 207, 1, 32]          --
│    │    └─STMetaGRUCell: 3-14          [64, 207, 1, 32]          --
│    │    └─STMetaGRUCell: 3-15          [64, 207, 1, 32]          --
├─Linear: 1-4                            [64, 207, 12]             396
==========================================================================================
Total params: 488,908
Trainable params: 488,908
Non-trainable params: 0
Total mult-adds (M): 30.44
==========================================================================================
Input size (MB): 1.91
Forward/backward pass size (MB): 408.25
Params size (MB): 1.90
Estimated Total Size (MB): 412.06
==========================================================================================

Loss: MaskedMAELoss

2023-04-16 18:37:37.252232 Epoch 1  	Train Loss = 4.00428 Val Loss = 3.35242
2023-04-16 18:37:57.150529 Epoch 2  	Train Loss = 3.40921 Val Loss = 3.23289
2023-04-16 18:38:17.038468 Epoch 3  	Train Loss = 3.28858 Val Loss = 3.12077
2023-04-16 18:38:37.151318 Epoch 4  	Train Loss = 3.20864 Val Loss = 3.09306
2023-04-16 18:38:57.262700 Epoch 5  	Train Loss = 3.15116 Val Loss = 3.04752
2023-04-16 18:39:17.323571 Epoch 6  	Train Loss = 3.11415 Val Loss = 3.04317
2023-04-16 18:39:37.337430 Epoch 7  	Train Loss = 3.08376 Val Loss = 3.01808
2023-04-16 18:39:57.388846 Epoch 8  	Train Loss = 3.06099 Val Loss = 3.00479
2023-04-16 18:40:17.403146 Epoch 9  	Train Loss = 3.03872 Val Loss = 3.01181
2023-04-16 18:40:37.498223 Epoch 10  	Train Loss = 3.02548 Val Loss = 3.00424
2023-04-16 18:40:57.590563 Epoch 11  	Train Loss = 2.97900 Val Loss = 2.97996
2023-04-16 18:41:17.640096 Epoch 12  	Train Loss = 2.97036 Val Loss = 2.98140
2023-04-16 18:41:37.686470 Epoch 13  	Train Loss = 2.96599 Val Loss = 2.98382
2023-04-16 18:41:57.723883 Epoch 14  	Train Loss = 2.96259 Val Loss = 2.97873
2023-04-16 18:42:17.750867 Epoch 15  	Train Loss = 2.96009 Val Loss = 2.97418
2023-04-16 18:42:37.775220 Epoch 16  	Train Loss = 2.95634 Val Loss = 2.97837
2023-04-16 18:42:57.797060 Epoch 17  	Train Loss = 2.95401 Val Loss = 2.97581
2023-04-16 18:43:17.854472 Epoch 18  	Train Loss = 2.95049 Val Loss = 2.98100
2023-04-16 18:43:37.795870 Epoch 19  	Train Loss = 2.94766 Val Loss = 2.97229
2023-04-16 18:43:57.732043 Epoch 20  	Train Loss = 2.94515 Val Loss = 2.97654
2023-04-16 18:44:17.660374 Epoch 21  	Train Loss = 2.94269 Val Loss = 2.95922
2023-04-16 18:44:37.580391 Epoch 22  	Train Loss = 2.94124 Val Loss = 2.97549
2023-04-16 18:44:57.504549 Epoch 23  	Train Loss = 2.93836 Val Loss = 2.96973
2023-04-16 18:45:17.426421 Epoch 24  	Train Loss = 2.93555 Val Loss = 2.96805
2023-04-16 18:45:37.327865 Epoch 25  	Train Loss = 2.93361 Val Loss = 2.96642
2023-04-16 18:45:57.271202 Epoch 26  	Train Loss = 2.93070 Val Loss = 2.97710
2023-04-16 18:46:17.197078 Epoch 27  	Train Loss = 2.92889 Val Loss = 2.96326
2023-04-16 18:46:37.117260 Epoch 28  	Train Loss = 2.92590 Val Loss = 2.97135
2023-04-16 18:46:57.046325 Epoch 29  	Train Loss = 2.92348 Val Loss = 2.97704
2023-04-16 18:47:17.016905 Epoch 30  	Train Loss = 2.92164 Val Loss = 2.97111
2023-04-16 18:47:36.961246 Epoch 31  	Train Loss = 2.92016 Val Loss = 2.96782
Early stopping at epoch: 31
Best at epoch 21:
Train Loss = 2.94269
Train RMSE = 5.96040, MAE = 2.91475, MAPE = 7.92883
Val Loss = 2.95922
Val RMSE = 6.35722, MAE = 3.01467, MAPE = 8.67579
--------- Test ---------
All Steps RMSE = 6.64200, MAE = 3.20781, MAPE = 9.30392
Step 1 RMSE = 4.16643, MAE = 2.34661, MAPE = 5.92006
Step 2 RMSE = 5.03433, MAE = 2.64123, MAPE = 6.96938
Step 3 RMSE = 5.61734, MAE = 2.85341, MAPE = 7.79824
Step 4 RMSE = 6.08856, MAE = 3.02119, MAPE = 8.49950
Step 5 RMSE = 6.46941, MAE = 3.15426, MAPE = 9.05941
Step 6 RMSE = 6.77485, MAE = 3.26998, MAPE = 9.53389
Step 7 RMSE = 7.01369, MAE = 3.36755, MAPE = 9.96154
Step 8 RMSE = 7.20441, MAE = 3.45017, MAPE = 10.29926
Step 9 RMSE = 7.37818, MAE = 3.51657, MAPE = 10.56780
Step 10 RMSE = 7.52169, MAE = 3.57241, MAPE = 10.79943
Step 11 RMSE = 7.62856, MAE = 3.62542, MAPE = 11.01049
Step 12 RMSE = 7.74670, MAE = 3.67506, MAPE = 11.22829
Inference time: 1.44 s
